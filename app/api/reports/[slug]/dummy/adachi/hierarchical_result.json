{
  "arguments": [
    {
      "arg_id": "Acsv-1_0",
      "argument": "農地周辺の野焼きの煙が住宅地に流れてくるため、規制の検討が必要である。",
      "x": 0.04109806,
      "y": 12.588313,
      "p": 0,
      "cluster_ids": [
        "0",
        "1_3",
        "2_8"
      ],
      "attributes": null,
      "url": null
    },
    {
      "arg_id": "Acsv-2_0",
      "argument": "学校の通学路に街灯が少なくて危険であるため、防犯対策の強化を求める。",
      "x": 0.33784485,
      "y": 10.685735,
      "p": 0,
      "cluster_ids": [
        "0",
        "1_1",
        "2_7"
      ],
      "attributes": null,
      "url": null
    },
    {
      "arg_id": "Acsv-3_0",
      "argument": "高齢者向け住宅の情報が不足しているため、相談窓口の設置を求めるべきである。",
      "x": -0.32129866,
      "y": 11.36019,
      "p": 0,
      "cluster_ids": [
        "0",
        "1_3",
        "2_2"
      ],
      "attributes": null,
      "url": null
    },
    {
      "arg_id": "Acsv-4_0",
      "argument": "住宅地の工場からの振動が家屋に影響を与えているため、振動測定を行うべきである。",
      "x": -0.9822282,
      "y": 11.0529585,
      "p": 0,
      "cluster_ids": [
        "0",
        "1_2",
        "2_1"
      ],
      "attributes": null,
      "url": null
    },
    {
      "arg_id": "Acsv-4_1",
      "argument": "振動に対する対策を講じる必要がある。",
      "x": -0.67215794,
      "y": 10.303006,
      "p": 0,
      "cluster_ids": [
        "0",
        "1_2",
        "2_1"
      ],
      "attributes": null,
      "url": null
    },
    {
      "arg_id": "Acsv-5_0",
      "argument": "工場の夜間操業音がうるさい",
      "x": -1.7496243,
      "y": 9.937505,
      "p": 0,
      "cluster_ids": [
        "0",
        "1_2",
        "2_4"
      ],
      "attributes": null,
      "url": null
    },
    {
      "arg_id": "Acsv-5_1",
      "argument": "住工混在地域の規制見直しを求める",
      "x": -0.5849839,
      "y": 11.940496,
      "p": 0,
      "cluster_ids": [
        "0",
        "1_3",
        "2_6"
      ],
      "attributes": null,
      "url": null
    },
    {
      "arg_id": "Acsv-6_0",
      "argument": "工業地域と住宅地の境界があいまいであるため、用途地域の見直しを検討すべき",
      "x": 0.61165565,
      "y": 12.224434,
      "p": 0,
      "cluster_ids": [
        "0",
        "1_1",
        "2_5"
      ],
      "attributes": null,
      "url": null
    },
    {
      "arg_id": "Acsv-7_0",
      "argument": "住工混在地域での騒音・振動問題が深刻であるため、用途地域の見直しを求めるべきである。",
      "x": -1.0695429,
      "y": 11.67023,
      "p": 0,
      "cluster_ids": [
        "0",
        "1_3",
        "2_6"
      ],
      "attributes": null,
      "url": null
    },
    {
      "arg_id": "Acsv-8_0",
      "argument": "荒川氾濫時の避難場所が遠すぎるため、近隣への避難所設置をお願いしたい。",
      "x": 1.1775572,
      "y": 11.0789,
      "p": 0,
      "cluster_ids": [
        "0",
        "1_1",
        "2_0"
      ],
      "attributes": null,
      "url": null
    },
    {
      "arg_id": "Acsv-9_0",
      "argument": "駅前再開発によって商店街が衰退しているため、地元商業の保護策を検討すべきである。",
      "x": 1.156781,
      "y": 12.202816,
      "p": 0,
      "cluster_ids": [
        "0",
        "1_1",
        "2_5"
      ],
      "attributes": null,
      "url": null
    },
    {
      "arg_id": "Acsv-10_0",
      "argument": "大学周辺の学生の騒音が深夜まで続いているため、指導が必要である。",
      "x": -1.7532518,
      "y": 10.382568,
      "p": 0,
      "cluster_ids": [
        "0",
        "1_2",
        "2_4"
      ],
      "attributes": null,
      "url": null
    },
    {
      "arg_id": "Acsv-11_0",
      "argument": "工場の夜間操業で振動がひどいため、操業時間の規制強化を求めるべきである。",
      "x": -1.7665004,
      "y": 10.989235,
      "p": 0,
      "cluster_ids": [
        "0",
        "1_2",
        "2_1"
      ],
      "attributes": null,
      "url": null
    },
    {
      "arg_id": "Acsv-12_0",
      "argument": "近所の工場からの振動で家の壁にひびが入ったため、調査をお願いしたい。",
      "x": -1.006655,
      "y": 10.646879,
      "p": 0,
      "cluster_ids": [
        "0",
        "1_2",
        "2_1"
      ],
      "attributes": null,
      "url": null
    },
    {
      "arg_id": "Acsv-13_0",
      "argument": "学校の冷房設備が故障しがちであるため、設備の更新をお願いしたい。",
      "x": 0.04862392,
      "y": 10.279278,
      "p": 0,
      "cluster_ids": [
        "0",
        "1_1",
        "2_7"
      ],
      "attributes": null,
      "url": null
    },
    {
      "arg_id": "Acsv-14_0",
      "argument": "河川の氾濫対策が不十分である。",
      "x": 1.634984,
      "y": 10.850986,
      "p": 0,
      "cluster_ids": [
        "0",
        "1_1",
        "2_0"
      ],
      "attributes": null,
      "url": null
    },
    {
      "arg_id": "Acsv-14_1",
      "argument": "堤防の強化工事を早急に実施すべきである。",
      "x": 0.5851844,
      "y": 11.33967,
      "p": 0,
      "cluster_ids": [
        "0",
        "1_1",
        "2_0"
      ],
      "attributes": null,
      "url": null
    },
    {
      "arg_id": "Acsv-15_0",
      "argument": "河川敷の不法占拠が景観を損ねているため、撤去と管理の強化を求める。",
      "x": 1.5936848,
      "y": 11.584328,
      "p": 0,
      "cluster_ids": [
        "0",
        "1_1",
        "2_0"
      ],
      "attributes": null,
      "url": null
    },
    {
      "arg_id": "Acsv-16_0",
      "argument": "工場の夜勤シフト交代時の騒音がうるさいため、時間帯の調整をお願いしたい。",
      "x": -1.2938902,
      "y": 9.791117,
      "p": 0,
      "cluster_ids": [
        "0",
        "1_2",
        "2_4"
      ],
      "attributes": null,
      "url": null
    },
    {
      "arg_id": "Acsv-17_0",
      "argument": "足立区の教育格差解消に向けた取り組みを強化すべき",
      "x": 0.77856976,
      "y": 10.211192,
      "p": 0,
      "cluster_ids": [
        "0",
        "1_1",
        "2_3"
      ],
      "attributes": null,
      "url": null
    },
    {
      "arg_id": "Acsv-17_1",
      "argument": "教育格差は子供の将来に関わる重要な問題である",
      "x": 0.5659373,
      "y": 9.757041,
      "p": 0,
      "cluster_ids": [
        "0",
        "1_1",
        "2_3"
      ],
      "attributes": null,
      "url": null
    },
    {
      "arg_id": "Acsv-18_0",
      "argument": "工場地帯の大気汚染がひどいので、環境基準の見直しが必要である。",
      "x": -0.4792214,
      "y": 12.425852,
      "p": 0,
      "cluster_ids": [
        "0",
        "1_3",
        "2_8"
      ],
      "attributes": null,
      "url": null
    },
    {
      "arg_id": "Acsv-18_1",
      "argument": "大気汚染対策の強化を求める。",
      "x": 0.043932606,
      "y": 11.918777,
      "p": 0,
      "cluster_ids": [
        "0",
        "1_3",
        "2_2"
      ],
      "attributes": null,
      "url": null
    },
    {
      "arg_id": "Acsv-19_0",
      "argument": "公園の防犯カメラが死角になっている場所があるため、設置場所の見直しをすべきである。",
      "x": 1.0140662,
      "y": 11.743713,
      "p": 0,
      "cluster_ids": [
        "0",
        "1_1",
        "2_5"
      ],
      "attributes": null,
      "url": null
    },
    {
      "arg_id": "Acsv-20_0",
      "argument": "近隣のカラオケボックスの音漏れで眠れないため、防音対策の指導を求めるべき。",
      "x": -2.1564517,
      "y": 10.4188795,
      "p": 0,
      "cluster_ids": [
        "0",
        "1_2",
        "2_4"
      ],
      "attributes": null,
      "url": null
    }
  ],
  "clusters": [
    {
      "level": 0,
      "id": "0",
      "label": "全体",
      "takeaway": "",
      "value": 25,
      "parent": "",
      "density_rank_percentile": 0
    },
    {
      "level": 1,
      "id": "1_3",
      "label": "地域住民の健康と生活環境を守るための包括的な環境政策の強化",
      "takeaway": "地域の大気汚染や騒音問題に対する具体的な対策が求められています。特に、農地周辺の野焼きや工場からの汚染物質が住民の健康に悪影響を及ぼすことから、環境基準の見直しが急務です。また、高齢者向け住宅に関する情報不足を解消するための相談窓口の設置や、住工混在地域における騒音・振動問題の解決に向けた用途地域の見直しが必要とされています。これらの施策を通じて、地域住民が安心して生活できる環境を整えることが重要です。",
      "value": 6,
      "parent": "0",
      "density_rank_percentile": 0.3333333333333333
    },
    {
      "level": 1,
      "id": "1_1",
      "label": "地域の安全性向上と教育格差解消に向けた具体的な取り組み",
      "takeaway": "地域の安全性を高めるための具体的な施策が求められています。通学路の安全確保や学校内の快適性向上、商業活動の保護、防犯対策の強化が重要視されており、特に河川管理や防災対策の強化が急務とされています。また、足立区における教育格差の解消が地域社会全体の発展に寄与するとの認識が広がっており、教育の平等を実現するための取り組みの強化が求められています。",
      "value": 11,
      "parent": "0",
      "density_rank_percentile": 1.0
    },
    {
      "level": 1,
      "id": "1_2",
      "label": "地域住民の生活環境を守るための振動・騒音対策の強化",
      "takeaway": "工場からの振動や夜間の騒音が地域住民の生活に深刻な影響を与えていることに対する懸念が高まっています。具体的には、振動による家屋の損傷や夜間の騒音が睡眠を妨げる問題が指摘されており、振動測定や騒音の時間帯調整、防音対策の実施が求められています。これにより、地域住民の生活環境を改善し、安心して暮らせる地域づくりが期待されています。",
      "value": 8,
      "parent": "0",
      "density_rank_percentile": 0.6666666666666666
    },
    {
      "level": 2,
      "id": "2_8",
      "label": "地域環境保護のための大気汚染対策の必要性",
      "takeaway": "この意見グループは、農地周辺の野焼きや工場地帯からの大気汚染が住宅地に影響を及ぼしていることに対する懸念が中心です。特に、煙や汚染物質が住民の健康や生活環境に悪影響を与える可能性があるため、規制や環境基準の見直しが求められています。",
      "value": 2,
      "parent": "1_3",
      "density_rank_percentile": 0.3333333333333333
    },
    {
      "level": 2,
      "id": "2_7",
      "label": "学校環境の安全性と快適性向上の要望",
      "takeaway": "この意見グループは、学校の通学路における安全性の確保と、学校内の冷房設備の改善に関する要望が中心です。通学路の街灯不足による危険性の指摘と、冷房設備の故障による快適性の低下を解消するための具体的な対策を求めています。",
      "value": 2,
      "parent": "1_1",
      "density_rank_percentile": 0.1111111111111111
    },
    {
      "level": 2,
      "id": "2_2",
      "label": "環境保護と高齢者支援のための政策提言",
      "takeaway": "この意見グループは、大気汚染対策の強化と高齢者向け住宅に関する情報不足の解消を求めるもので、環境保護と高齢者支援という異なるが重要な社会的課題に対する政策提言が中心です。具体的には、環境問題への取り組みと高齢者が安心して生活できるための相談窓口の設置が求められています。",
      "value": 2,
      "parent": "1_3",
      "density_rank_percentile": 0.6666666666666666
    },
    {
      "level": 2,
      "id": "2_1",
      "label": "工場振動による住宅影響と対策要望",
      "takeaway": "この意見グループは、近所の工場からの振動が住宅に与える影響に関する懸念が中心です。具体的には、振動による家屋の損傷や影響を調査する必要性、振動測定の実施、さらには工場の操業時間に対する規制強化を求める声が挙がっています。これらの意見は、地域住民の生活環境を守るための具体的な対策を求めるものです。",
      "value": 4,
      "parent": "1_2",
      "density_rank_percentile": 0.8888888888888888
    },
    {
      "level": 2,
      "id": "2_4",
      "label": "夜間騒音問題と防音対策の必要性",
      "takeaway": "この意見グループは、工場や周辺の騒音が夜間の生活に与える影響に対する懸念が中心です。具体的には、工場の夜勤シフト交代時の騒音や近隣のカラオケボックス、大学周辺の学生による騒音が問題視されており、これらの騒音に対する時間帯の調整や防音対策の指導が求められています。",
      "value": 4,
      "parent": "1_2",
      "density_rank_percentile": 0.7777777777777778
    },
    {
      "level": 2,
      "id": "2_6",
      "label": "住工混在地域における騒音・振動問題の解決と用途地域の見直し",
      "takeaway": "この意見グループは、住工混在地域における騒音や振動の問題が深刻であることを背景に、用途地域の見直しを求める声が中心です。住環境と工業活動の調和を図るために、規制の再検討が必要であるという具体的な提案が含まれています。",
      "value": 2,
      "parent": "1_3",
      "density_rank_percentile": 0.4444444444444444
    },
    {
      "level": 2,
      "id": "2_5",
      "label": "地域の安全と商業活性化に向けた政策提言",
      "takeaway": "この意見グループは、地域の商業活動の保護や防犯対策、用途地域の見直しといった、地域の安全性や商業の活性化に関する具体的な政策提言が中心です。駅前再開発による商店街の衰退を懸念し、地元商業の保護策を求める声や、防犯カメラの設置見直し、工業地域と住宅地の境界の明確化を通じて、地域全体の安全性と住みやすさを向上させる必要性が強調されています。",
      "value": 3,
      "parent": "1_1",
      "density_rank_percentile": 0.5555555555555556
    },
    {
      "level": 2,
      "id": "2_0",
      "label": "河川管理と防災対策の強化",
      "takeaway": "この意見グループは、河川の氾濫対策や管理の不十分さに対する懸念が中心であり、堤防の強化や不法占拠の撤去、避難所の設置など、具体的な対策の必要性が強調されています。特に、地域住民の安全を確保するための迅速な対応が求められています。",
      "value": 4,
      "parent": "1_1",
      "density_rank_percentile": 1.0
    },
    {
      "level": 2,
      "id": "2_3",
      "label": "足立区における教育格差解消の重要性と取り組み強化",
      "takeaway": "この意見グループは、足立区における教育格差が子供たちの将来に深刻な影響を及ぼすことを強調し、その解消に向けた具体的な取り組みの強化が必要であるという認識が共有されています。教育の平等を実現することが、地域社会全体の発展にも寄与するという視点が見受けられます。",
      "value": 2,
      "parent": "1_1",
      "density_rank_percentile": 0.2222222222222222
    }
  ],
  "comments": {},
  "propertyMap": {},
  "translations": {},
  "overview": "地域住民の健康と生活環境を守るため、包括的な環境政策の強化が求められています。具体的には、大気汚染や騒音問題への対策、教育格差の解消、振動・騒音対策の強化が重要視されています。これらの施策を通じて、住民が安心して生活できる環境の整備が期待されています。特に、相談窓口の設置や用途地域の見直しが急務とされています。",
  "config": {
    "name": "adachi",
    "input": "adachi",
    "question": "足立区",
    "intro": "足立区の分析\n分析対象となったデータの件数は20件で、これらのデータに対してOpenAI API (gpt-4o-mini)を用いて25件の意見（議論）を抽出し、クラスタリングを行った。\n",
    "model": "gpt-4o-mini",
    "provider": "openai",
    "is_pubcom": true,
    "is_embedded_at_local": false,
    "local_llm_address": null,
    "extraction": {
      "prompt": "あなたは専門的なリサーチアシスタントです。与えられたテキストから、意見を抽出して整理してください。\n\n# 指示\n* 入出力の例に記載したような形式で文字列のリストを返してください\n  * 必要な場合は2つの別個の意見に分割してください。多くの場合は1つの議論にまとめる方が望ましいです。\n* 整理した意見は日本語で出力してください\n\n## 入出力の例\n/human\n\nAIテクノロジーは、そのライフサイクル全体における環境負荷を削減することに焦点を当てて開発されるべきです。\n\n/ai\n\n{\n  \"extractedOpinionList\": [\n    \"AIテクノロジーは、そのライフサイクル全体における環境負荷を削減することに焦点を当てて開発されるべきです。\"\n  ]\n}\n\n/human\n\nAIの能力、限界、倫理的考慮事項について、市民を教育する必要がある。また、教育できる人材を養成する必要がある。\n\n/ai\n\n{\n  \"extractedOpinionList\": [\n    \"AIの能力、限界、倫理的考慮事項について、市民を教育すべき\",\n    \"AIに関する教育をできる人材を養成すべき\"\n  ]\n}\n\n/human\n\nAIはエネルギーグリッドを最適化し、無駄や炭素排出を削減できます。\n\n/ai\n\n{\n  \"extractedOpinionList\": [\n    \"AIはエネルギーグリッドを最適化して炭素排出を削減できる\"\n  ]\n}\n",
      "workers": 30,
      "limit": 20,
      "properties": [],
      "categories": {},
      "category_batch_size": 5,
      "source_code": "import concurrent.futures\nimport json\nimport logging\nimport re\n\nimport pandas as pd\nfrom pydantic import BaseModel, Field\nfrom tqdm import tqdm\n\nfrom services.category_classification import classify_args\nfrom services.llm import request_to_chat_ai\nfrom services.parse_json_list import parse_extraction_response\nfrom utils import update_progress\n\nCOMMA_AND_SPACE_AND_RIGHT_BRACKET = re.compile(r\",\\s*(\\])\")\n\n\nclass ExtractionResponse(BaseModel):\n    extractedOpinionList: list[str] = Field(..., description=\"抽出した意見のリスト\")\n\n\ndef _validate_property_columns(property_columns: list[str], comments: pd.DataFrame) -> None:\n    if not all(property in comments.columns for property in property_columns):\n        raise ValueError(f\"Properties {property_columns} not found in comments. Columns are {comments.columns}\")\n\n\ndef extraction(config):\n    dataset = config[\"output_dir\"]\n    path = f\"outputs/{dataset}/args.csv\"\n    model = config[\"extraction\"][\"model\"]\n    prompt = config[\"extraction\"][\"prompt\"]\n    workers = config[\"extraction\"][\"workers\"]\n    limit = config[\"extraction\"][\"limit\"]\n    property_columns = config[\"extraction\"][\"properties\"]\n\n    if \"provider\" not in config:\n        raise RuntimeError(\"provider is not set\")\n    provider = config[\"provider\"]\n\n    # カラム名だけを読み込み、必要なカラムが含まれているか確認する\n    comments = pd.read_csv(f\"inputs/{config['input']}.csv\", nrows=0)\n    _validate_property_columns(property_columns, comments)\n    # エラーが出なかった場合、すべての行を読み込む\n    comments = pd.read_csv(\n        f\"inputs/{config['input']}.csv\", usecols=[\"comment-id\", \"comment-body\"] + config[\"extraction\"][\"properties\"]\n    )\n    comment_ids = (comments[\"comment-id\"].values)[:limit]\n    comments.set_index(\"comment-id\", inplace=True)\n    results = pd.DataFrame()\n    update_progress(config, total=len(comment_ids))\n\n    argument_map = {}\n    relation_rows = []\n\n    for i in tqdm(range(0, len(comment_ids), workers)):\n        batch = comment_ids[i : i + workers]\n        batch_inputs = [comments.loc[id][\"comment-body\"] for id in batch]\n        batch_results = extract_batch(\n            batch_inputs, prompt, model, workers, provider, config.get(\"local_llm_address\"), config\n        )\n\n        for comment_id, extracted_args in zip(batch, batch_results, strict=False):\n            for j, arg in enumerate(extracted_args):\n                if arg not in argument_map:\n                    # argumentテーブルに追加\n                    arg_id = f\"A{comment_id}_{j}\"\n                    argument = arg\n                    argument_map[arg] = {\n                        \"arg-id\": arg_id,\n                        \"argument\": argument,\n                    }\n                else:\n                    arg_id = argument_map[arg][\"arg-id\"]\n\n                # relationテーブルにcommentとargの関係を追加\n                relation_row = {\n                    \"arg-id\": arg_id,\n                    \"comment-id\": comment_id,\n                }\n                relation_rows.append(relation_row)\n\n        update_progress(config, incr=len(batch))\n\n    # DataFrame化\n    results = pd.DataFrame(argument_map.values())\n    relation_df = pd.DataFrame(relation_rows)\n\n    if results.empty:\n        raise RuntimeError(\"result is empty, maybe bad prompt\")\n\n    classification_categories = config[\"extraction\"][\"categories\"]\n    if classification_categories:\n        results = classify_args(results, config, workers)\n\n    results.to_csv(path, index=False)\n    # comment-idとarg-idの関係を保存\n    relation_df.to_csv(f\"outputs/{dataset}/relations.csv\", index=False)\n\n\nlogging.basicConfig(level=logging.ERROR)\n\n\ndef extract_batch(batch, prompt, model, workers, provider=\"openai\", local_llm_address=None, config=None):\n    with concurrent.futures.ThreadPoolExecutor(max_workers=workers) as executor:\n        futures_with_index = [\n            (i, executor.submit(extract_arguments, input, prompt, model, provider, local_llm_address))\n            for i, input in enumerate(batch)\n        ]\n\n        done, not_done = concurrent.futures.wait([f for _, f in futures_with_index], timeout=30)\n        results = [[] for _ in range(len(batch))]\n        total_token_input = 0\n        total_token_output = 0\n        total_token_usage = 0\n\n        for _, future in futures_with_index:\n            if future in not_done and not future.cancelled():\n                future.cancel()\n\n        for i, future in futures_with_index:\n            if future in done:\n                try:\n                    result = future.result()\n                    if isinstance(result, tuple) and len(result) == 4:\n                        items, token_input, token_output, token_total = result\n                        results[i] = items\n                        total_token_input += token_input\n                        total_token_output += token_output\n                        total_token_usage += token_total\n                    else:\n                        results[i] = result\n                except Exception as e:\n                    logging.error(f\"Task {future} failed with error: {e}\")\n                    results[i] = []\n\n        if config is not None:\n            config[\"total_token_usage\"] = config.get(\"total_token_usage\", 0) + total_token_usage\n            config[\"token_usage_input\"] = config.get(\"token_usage_input\", 0) + total_token_input\n            config[\"token_usage_output\"] = config.get(\"token_usage_output\", 0) + total_token_output\n            print(\n                f\"Extraction batch: input={total_token_input}, output={total_token_output}, total={total_token_usage} tokens\"\n            )\n\n        return results\n\n\ndef extract_arguments(input, prompt, model, provider=\"openai\", local_llm_address=None):\n    messages = [\n        {\"role\": \"system\", \"content\": prompt},\n        {\"role\": \"user\", \"content\": input},\n    ]\n    try:\n        response, token_input, token_output, token_total = request_to_chat_ai(\n            messages=messages,\n            model=model,\n            is_json=False,\n            json_schema=ExtractionResponse,\n            provider=provider,\n            local_llm_address=local_llm_address,\n        )\n        items = parse_extraction_response(response)\n        items = list(filter(None, items))  # omit empty strings\n        return items, token_input, token_output, token_total\n    except json.decoder.JSONDecodeError as e:\n        print(\"JSON error:\", e)\n        print(\"Input was:\", input)\n        print(\"Response was:\", response)\n        print(\"Silently giving up on trying to generate valid list.\")\n        return []\n",
      "model": "gpt-4o-mini"
    },
    "hierarchical_clustering": {
      "cluster_nums": [
        3,
        9
      ],
      "source_code": "\"\"\"Cluster the arguments using UMAP + HDBSCAN and GPT-4.\"\"\"\n\nfrom importlib import import_module\n\nimport numpy as np\nimport pandas as pd\nimport scipy.cluster.hierarchy as sch\nfrom sklearn.cluster import KMeans\n\n\ndef hierarchical_clustering(config):\n    UMAP = import_module(\"umap\").UMAP\n\n    dataset = config[\"output_dir\"]\n    path = f\"outputs/{dataset}/hierarchical_clusters.csv\"\n    arguments_df = pd.read_csv(f\"outputs/{dataset}/args.csv\", usecols=[\"arg-id\", \"argument\"])\n    embeddings_df = pd.read_pickle(f\"outputs/{dataset}/embeddings.pkl\")\n    embeddings_array = np.asarray(embeddings_df[\"embedding\"].values.tolist())\n    cluster_nums = config[\"hierarchical_clustering\"][\"cluster_nums\"]\n\n    n_samples = embeddings_array.shape[0]\n    # デフォルト設定は15\n    default_n_neighbors = 15\n\n    # テスト等サンプルが少なすぎる場合、n_neighborsの設定値を下げる\n    if n_samples <= default_n_neighbors:\n        n_neighbors = max(2, n_samples - 1)  # 最低2以上\n    else:\n        n_neighbors = default_n_neighbors\n\n    umap_model = UMAP(random_state=42, n_components=2, n_neighbors=n_neighbors)\n    # TODO 詳細エラーメッセージを加える\n    # 以下のエラーの場合、おそらく元の意見件数が少なすぎることが原因\n    # TypeError: Cannot use scipy.linalg.eigh for sparse A with k >= N. Use scipy.linalg.eigh(A.toarray()) or reduce k.\n    umap_embeds = umap_model.fit_transform(embeddings_array)\n\n    cluster_results = hierarchical_clustering_embeddings(\n        umap_embeds=umap_embeds,\n        cluster_nums=cluster_nums,\n    )\n    result_df = pd.DataFrame(\n        {\n            \"arg-id\": arguments_df[\"arg-id\"],\n            \"argument\": arguments_df[\"argument\"],\n            \"x\": umap_embeds[:, 0],\n            \"y\": umap_embeds[:, 1],\n        }\n    )\n\n    for cluster_level, final_labels in enumerate(cluster_results.values(), start=1):\n        result_df[f\"cluster-level-{cluster_level}-id\"] = [f\"{cluster_level}_{label}\" for label in final_labels]\n\n    result_df.to_csv(path, index=False)\n\n\ndef generate_cluster_count_list(min_clusters: int, max_clusters: int):\n    cluster_counts = []\n    current = min_clusters\n    cluster_counts.append(current)\n\n    if min_clusters == max_clusters:\n        return cluster_counts\n\n    while True:\n        next_double = current * 2\n        next_triple = current * 3\n\n        if next_double >= max_clusters:\n            if cluster_counts[-1] != max_clusters:\n                cluster_counts.append(max_clusters)\n            break\n\n        # 次の倍はまだ max_clusters に収まるが、3倍だと超える\n        # -> (次の倍は細かすぎるので)スキップして max_clusters に飛ぶ\n        if next_triple > max_clusters:\n            cluster_counts.append(max_clusters)\n            break\n\n        cluster_counts.append(next_double)\n        current = next_double\n\n    return cluster_counts\n\n\ndef merge_clusters_with_hierarchy(\n    cluster_centers: np.ndarray,\n    kmeans_labels: np.ndarray,\n    umap_array: np.ndarray,\n    n_cluster_cut: int,\n):\n    Z = sch.linkage(cluster_centers, method=\"ward\")\n    cluster_labels_merged = sch.fcluster(Z, t=n_cluster_cut, criterion=\"maxclust\")\n\n    n_samples = umap_array.shape[0]\n    final_labels = np.zeros(n_samples, dtype=int)\n\n    for i in range(n_samples):\n        original_label = kmeans_labels[i]\n        final_labels[i] = cluster_labels_merged[original_label]\n\n    return final_labels\n\n\ndef hierarchical_clustering_embeddings(\n    umap_embeds,\n    cluster_nums,\n):\n    # 最大分割数でクラスタリングを実施\n    print(\"start initial clustering\")\n    initial_cluster_num = cluster_nums[-1]\n    kmeans_model = KMeans(n_clusters=initial_cluster_num, random_state=42)\n    kmeans_model.fit(umap_embeds)\n    print(\"end initial clustering\")\n\n    results = {}\n    print(\"start hierarchical clustering\")\n    cluster_nums.sort()\n    print(cluster_nums)\n    for n_cluster_cut in cluster_nums[:-1]:\n        print(\"n_cluster_cut: \", n_cluster_cut)\n        final_labels = merge_clusters_with_hierarchy(\n            cluster_centers=kmeans_model.cluster_centers_,\n            kmeans_labels=kmeans_model.labels_,\n            umap_array=umap_embeds,\n            n_cluster_cut=n_cluster_cut,\n        )\n        results[n_cluster_cut] = final_labels\n\n    results[initial_cluster_num] = kmeans_model.labels_\n    print(\"end hierarchical clustering\")\n\n    return results\n"
    },
    "hierarchical_initial_labelling": {
      "prompt": "あなたはKJ法が得意なデータ分析者です。userのinputはグループに集まったラベルです。なぜそのラベルが一つのグループであるか解説し、表札（label）をつけてください。\n表札については、グループ内の具体的な論点や特徴を反映した、具体性の高い名称を考案してください。\n出力はJSONとし、フォーマットは以下のサンプルを参考にしてください。\n\n\n# サンプルの入出力\n## 入力例\n- 手作業での意見分析は時間がかかりすぎる。AIで効率化できると嬉しい\n- 今のやり方だと分析に工数がかかりすぎるけど、AIならコストをかけずに分析できそう\n- AIが自動で意見を整理してくれると楽になって嬉しい\n\n\n## 出力例\n{\n    \"label\": \"AIによる業務効率の大幅向上とコスト効率化\",\n    \"description\": \"この意見グループは、従来の手作業による意見分析と比較して、AIによる自動化で分析プロセスが効率化され、作業時間の短縮や運用コストの効率化が実現される点に対する前向きな評価が中心です。\"\n}\n",
      "sampling_num": 30,
      "workers": 30,
      "source_code": "import json\nfrom concurrent.futures import ThreadPoolExecutor\nfrom functools import partial\nfrom typing import TypedDict\n\nimport pandas as pd\nfrom pydantic import BaseModel, Field\n\nfrom services.llm import request_to_chat_ai\n\n\nclass LabellingResult(TypedDict):\n    \"\"\"各クラスタのラベリング結果を表す型\"\"\"\n\n    cluster_id: str  # クラスタのID\n    label: str  # クラスタのラベル名\n    description: str  # クラスタの説明文\n\n\ndef hierarchical_initial_labelling(config: dict) -> None:\n    \"\"\"階層的クラスタリングの初期ラベリングを実行する\n\n    Args:\n        config: 設定情報を含む辞書\n            - output_dir: 出力ディレクトリ名\n            - hierarchical_initial_labelling: 初期ラベリングの設定\n                - sampling_num: サンプリング数\n                - prompt: LLMへのプロンプト\n                - model: 使用するLLMモデル名\n                - workers: 並列処理のワーカー数\n            - provider: LLMプロバイダー\n    \"\"\"\n    dataset = config[\"output_dir\"]\n    path = f\"outputs/{dataset}/hierarchical_initial_labels.csv\"\n    clusters_argument_df = pd.read_csv(f\"outputs/{dataset}/hierarchical_clusters.csv\")\n\n    cluster_id_columns = [col for col in clusters_argument_df.columns if col.startswith(\"cluster-level-\")]\n    initial_cluster_id_column = cluster_id_columns[-1]\n    sampling_num = config[\"hierarchical_initial_labelling\"][\"sampling_num\"]\n    initial_labelling_prompt = config[\"hierarchical_initial_labelling\"][\"prompt\"]\n    model = config[\"hierarchical_initial_labelling\"][\"model\"]\n    workers = config[\"hierarchical_initial_labelling\"][\"workers\"]\n\n    # トークン使用量を追跡するための変数を初期化\n    config[\"total_token_usage\"] = config.get(\"total_token_usage\", 0)\n\n    initial_label_df = initial_labelling(\n        initial_labelling_prompt,\n        clusters_argument_df,\n        sampling_num,\n        model,\n        workers,\n        config[\"provider\"],\n        config.get(\"local_llm_address\"),\n        config,  # configを渡して、トークン使用量を累積できるようにする\n    )\n    print(\"start initial labelling\")\n    initial_clusters_argument_df = clusters_argument_df.merge(\n        initial_label_df,\n        left_on=initial_cluster_id_column,\n        right_on=\"cluster_id\",\n        how=\"left\",\n    ).rename(\n        columns={\n            \"label\": f\"{initial_cluster_id_column.replace('-id', '')}-label\",\n            \"description\": f\"{initial_cluster_id_column.replace('-id', '')}-description\",\n        }\n    )\n    print(\"end initial labelling\")\n    initial_clusters_argument_df.to_csv(path, index=False)\n\n\ndef initial_labelling(\n    prompt: str,\n    clusters_df: pd.DataFrame,\n    sampling_num: int,\n    model: str,\n    workers: int,\n    provider: str = \"openai\",\n    local_llm_address: str | None = None,\n    config: dict | None = None,  # configを追加\n) -> pd.DataFrame:\n    \"\"\"各クラスタに対して初期ラベリングを実行する\n\n    Args:\n        prompt: LLMへのプロンプト\n        clusters_df: クラスタリング結果のDataFrame\n        sampling_num: 各クラスタからサンプリングする意見の数\n        model: 使用するLLMモデル名\n        workers: 並列処理のワーカー数\n        provider: LLMプロバイダー\n        local_llm_address: ローカルLLMのアドレス\n        config: 設定情報を含む辞書（トークン使用量の累積に使用）\n\n    Returns:\n        各クラスタのラベリング結果を含むDataFrame\n    \"\"\"\n    cluster_columns = [col for col in clusters_df.columns if col.startswith(\"cluster-level-\")]\n    initial_cluster_column = cluster_columns[-1]\n    cluster_ids = clusters_df[initial_cluster_column].unique()\n    process_func = partial(\n        process_initial_labelling,\n        df=clusters_df,\n        prompt=prompt,\n        sampling_num=sampling_num,\n        target_column=initial_cluster_column,\n        model=model,\n        provider=provider,\n        local_llm_address=local_llm_address,\n        config=config,  # configを渡す\n    )\n    with ThreadPoolExecutor(max_workers=workers) as executor:\n        results = list(executor.map(process_func, cluster_ids))\n    return pd.DataFrame(results)\n\n\nclass LabellingFromat(BaseModel):\n    \"\"\"ラベリング結果のフォーマットを定義する\"\"\"\n\n    label: str = Field(..., description=\"クラスタのラベル名\")\n    description: str = Field(..., description=\"クラスタの説明文\")\n\n\ndef process_initial_labelling(\n    cluster_id: str,\n    df: pd.DataFrame,\n    prompt: str,\n    sampling_num: int,\n    target_column: str,\n    model: str,\n    provider: str = \"openai\",\n    local_llm_address: str | None = None,\n    config: dict | None = None,  # configを追加\n) -> LabellingResult:\n    \"\"\"個別のクラスタに対してラベリングを実行する\n\n    Args:\n        cluster_id: 処理対象のクラスタID\n        df: クラスタリング結果のDataFrame\n        prompt: LLMへのプロンプト\n        sampling_num: サンプリングする意見の数\n        target_column: クラスタIDが格納されている列名\n        model: 使用するLLMモデル名\n        provider: LLMプロバイダー\n        local_llm_address: ローカルLLMのアドレス\n        config: 設定情報を含む辞書（トークン使用量の累積に使用）\n\n    Returns:\n        クラスタのラベリング結果\n    \"\"\"\n    cluster_data = df[df[target_column] == cluster_id]\n    sampling_num = min(sampling_num, len(cluster_data))\n    cluster = cluster_data.sample(sampling_num)\n    input = \"\\n\".join(cluster[\"argument\"].values)\n    messages = [\n        {\"role\": \"system\", \"content\": prompt},\n        {\"role\": \"user\", \"content\": input},\n    ]\n    try:\n        response_text, token_input, token_output, token_total = request_to_chat_ai(\n            messages=messages,\n            model=model,\n            provider=provider,\n            json_schema=LabellingFromat,\n            local_llm_address=local_llm_address,\n        )\n\n        # トークン使用量を累積（configが渡されている場合）\n        if config is not None:\n            config[\"total_token_usage\"] = config.get(\"total_token_usage\", 0) + token_total\n            config[\"token_usage_input\"] = config.get(\"token_usage_input\", 0) + token_input\n            config[\"token_usage_output\"] = config.get(\"token_usage_output\", 0) + token_output\n\n        response_json = json.loads(response_text) if isinstance(response_text, str) else response_text\n        return LabellingResult(\n            cluster_id=cluster_id,\n            label=response_json.get(\"label\", \"エラーでラベル名が取得できませんでした\"),\n            description=response_json.get(\"description\", \"エラーで解説が取得できませんでした\"),\n        )\n    except Exception as e:\n        print(e)\n        return LabellingResult(\n            cluster_id=cluster_id,\n            label=\"エラーでラベル名が取得できませんでした\",\n            description=\"エラーで解説が取得できませんでした\",\n        )\n",
      "model": "gpt-4o-mini"
    },
    "hierarchical_merge_labelling": {
      "prompt": "あなたはデータ分析のエキスパートです。\n現在、テキストデータの階層クラスタリングを行っています。\n下層のクラスタ（意見グループ）のタイトルと説明、およびそれらのクラスタが所属する上層のクラスタのテキストのサンプルを与えるので、上層のクラスタのタイトルと説明を作成してください。\n\n# 指示\n- 統合後のクラスタ名は、統合前のクラスタ名称をそのまま引用せず、内容に基づいた新たな名称にしてください。\n- タイトルには、具体的な事象・行動（例：地域ごとの迅速対応、復興計画の着実な進展、効果的な情報共有・地域協力など）を含めてください\n  - 可能な限り具体的な表現を用いるようにし、抽象的な表現は避けてください\n    - 「多様な意見」などの抽象的な表現は避けてください\n- 出力例に示したJSON形式で出力してください\n\n\n# サンプルの入出力\n## 入力例\n- 「顧客フィードバックの自動集約」: この意見グループは、SNSやオンラインレビューなどから集めた大量の意見をAIが瞬時に解析し、企業が市場のトレンドや顧客の要望を即時に把握できる点についての期待を示しています。\n- 「AIによる業務効率の大幅向上とコスト効率化」: この意見グループは、従来の手作業による意見分析と比較して、AIによる自動化で分析プロセスが効率化され、作業時間の短縮や運用コストの効率化が実現される点に対する前向きな評価が中心です。\n\n## 出力例\n{\n    \"label\": \"AI技術の導入による意見分析の効率化への期待\",\n    \"description\": \"大量の意見やフィードバックから迅速に洞察を抽出できるため、企業や自治体が消費者や市民の声を的確に把握し、戦略的な意思決定やサービス改善が可能になります。また、従来の手法と比べて作業負荷が軽減され、業務効率の向上やコスト削減といった実際の便益が得られると期待されています。\"\n}\n",
      "sampling_num": 30,
      "workers": 30,
      "source_code": "import json\nfrom concurrent.futures import ThreadPoolExecutor\nfrom dataclasses import dataclass\nfrom functools import partial\n\nimport numpy as np\nimport pandas as pd\nfrom pydantic import BaseModel, Field\nfrom tqdm import tqdm\n\nfrom services.llm import request_to_chat_ai\n\n\n@dataclass\nclass ClusterColumns:\n    \"\"\"同一階層のクラスター関連のカラム名を管理するクラス\"\"\"\n\n    id: str\n    label: str\n    description: str\n\n    @classmethod\n    def from_id_column(cls, id_column: str) -> \"ClusterColumns\":\n        \"\"\"ID列名から関連するカラム名を生成\"\"\"\n        return cls(\n            id=id_column,\n            label=id_column.replace(\"-id\", \"-label\"),\n            description=id_column.replace(\"-id\", \"-description\"),\n        )\n\n\n@dataclass\nclass ClusterValues:\n    \"\"\"対象クラスタのlabel/descriptionを管理するクラス\"\"\"\n\n    label: str\n    description: str\n\n    def to_prompt_text(self) -> str:\n        return f\"- {self.label}: {self.description}\"\n\n\ndef hierarchical_merge_labelling(config: dict) -> None:\n    \"\"\"階層的クラスタリングの結果に対してマージラベリングを実行する\n\n    Args:\n        config: 設定情報を含む辞書\n            - output_dir: 出力ディレクトリ名\n            - hierarchical_merge_labelling: マージラベリングの設定\n                - sampling_num: サンプリング数\n                - prompt: LLMへのプロンプト\n                - model: 使用するLLMモデル名\n                - workers: 並列処理のワーカー数\n            - provider: LLMプロバイダー\n    \"\"\"\n    dataset = config[\"output_dir\"]\n    merge_path = f\"outputs/{dataset}/hierarchical_merge_labels.csv\"\n    clusters_df = pd.read_csv(f\"outputs/{dataset}/hierarchical_initial_labels.csv\")\n\n    cluster_id_columns: list[str] = _filter_id_columns(clusters_df.columns)\n    # ボトムクラスタのラベル・説明とクラスタid付きの各argumentを入力し、各階層のクラスタラベル・説明を生成し、argumentに付けたdfを作成\n    merge_result_df = merge_labelling(\n        clusters_df=clusters_df,\n        cluster_id_columns=sorted(cluster_id_columns, reverse=True),\n        config=config,\n    )\n    # 上記のdfから各クラスタのlevel, id, label, description, valueを取得してdfを作成\n    melted_df = melt_cluster_data(merge_result_df)\n    # 上記のdfに親子関係を追加\n    parent_child_df = _build_parent_child_mapping(merge_result_df, cluster_id_columns)\n    melted_df = melted_df.merge(parent_child_df, on=[\"level\", \"id\"], how=\"left\")\n    density_df = calculate_cluster_density(melted_df, config)\n    density_df.to_csv(merge_path, index=False)\n\n\ndef _build_parent_child_mapping(df: pd.DataFrame, cluster_id_columns: list[str]):\n    \"\"\"クラスタ間の親子関係をマッピングする\n\n    Args:\n        df: クラスタリング結果のDataFrame\n        cluster_id_columns: クラスタIDのカラム名のリスト\n\n    Returns:\n        親子関係のマッピング情報を含むDataFrame\n    \"\"\"\n    results = []\n    top_cluster_column = cluster_id_columns[0]\n    top_cluster_values = df[top_cluster_column].unique()\n    for c in top_cluster_values:\n        results.append(\n            {\n                \"level\": 1,\n                \"id\": c,\n                \"parent\": \"0\",  # aggregationで追加する全体クラスタのid\n            }\n        )\n\n    for idx in range(len(cluster_id_columns) - 1):\n        current_column = cluster_id_columns[idx]\n        children_column = cluster_id_columns[idx + 1]\n        current_level = current_column.replace(\"-id\", \"\").replace(\"cluster-level-\", \"\")\n        # 現在のレベルのクラスタid\n        current_cluster_values = df[current_column].unique()\n        for current_id in current_cluster_values:\n            children_ids = df.loc[df[current_column] == current_id, children_column].unique()\n            for child_id in children_ids:\n                results.append(\n                    {\n                        \"level\": int(current_level) + 1,\n                        \"id\": child_id,\n                        \"parent\": current_id,\n                    }\n                )\n    return pd.DataFrame(results)\n\n\ndef _filter_id_columns(columns: list[str]) -> list[str]:\n    \"\"\"クラスタIDのカラム名をフィルタリングする\n\n    Args:\n        columns: 全カラム名のリスト\n\n    Returns:\n        クラスタIDのカラム名のリスト\n    \"\"\"\n    return [col for col in columns if col.startswith(\"cluster-level-\") and col.endswith(\"-id\")]\n\n\ndef melt_cluster_data(df: pd.DataFrame) -> pd.DataFrame:\n    \"\"\"クラスタデータを行形式に変換する\n\n    cluster-level-n-(id|label|description) を行形式 (level, id, label, description, value) にまとめる。\n    [cluster-level-n-id, cluster-level-n-label, cluster-level-n-description] を [level, id, label, description, value(件数)] に変換する。\n\n    Args:\n        df: クラスタリング結果のDataFrame\n\n    Returns:\n        行形式に変換されたDataFrame\n    \"\"\"\n    id_columns: list[str] = _filter_id_columns(df.columns)\n    levels: set[int] = {int(col.replace(\"cluster-level-\", \"\").replace(\"-id\", \"\")) for col in id_columns}\n    all_rows: list[dict] = []\n\n    # levelごとに各クラスタの出現件数を集計・縦持ちにする\n    for level in levels:\n        cluster_columns = ClusterColumns.from_id_column(f\"cluster-level-{level}-id\")\n        # クラスタidごとの件数集計\n        level_count_df = df.groupby(cluster_columns.id).size().reset_index(name=\"value\")\n\n        level_unique_val_df = df[\n            [cluster_columns.id, cluster_columns.label, cluster_columns.description]\n        ].drop_duplicates()\n        level_unique_val_df = level_unique_val_df.merge(level_count_df, on=cluster_columns.id, how=\"left\")\n        level_unique_vals = [\n            {\n                \"level\": level,\n                \"id\": row[cluster_columns.id],\n                \"label\": row[cluster_columns.label],\n                \"description\": row[cluster_columns.description],\n                \"value\": row[\"value\"],\n            }\n            for _, row in level_unique_val_df.iterrows()\n        ]\n        all_rows.extend(level_unique_vals)\n    return pd.DataFrame(all_rows)\n\n\ndef merge_labelling(clusters_df: pd.DataFrame, cluster_id_columns: list[str], config) -> pd.DataFrame:\n    \"\"\"階層的なクラスタのマージラベリングを実行する\n\n    Args:\n        clusters_df: クラスタリング結果のDataFrame\n        cluster_id_columns: クラスタIDのカラム名のリスト\n        config: 設定情報を含む辞書\n\n    Returns:\n        マージラベリング結果を含むDataFrame\n    \"\"\"\n    for idx in tqdm(range(len(cluster_id_columns) - 1)):\n        previous_columns = ClusterColumns.from_id_column(cluster_id_columns[idx])\n        current_columns = ClusterColumns.from_id_column(cluster_id_columns[idx + 1])\n\n        process_fn = partial(\n            process_merge_labelling,\n            result_df=clusters_df,\n            current_columns=current_columns,\n            previous_columns=previous_columns,\n            config=config,\n        )\n\n        current_cluster_ids = sorted(clusters_df[current_columns.id].unique())\n        with ThreadPoolExecutor(max_workers=config[\"hierarchical_merge_labelling\"][\"workers\"]) as executor:\n            responses = list(\n                tqdm(\n                    executor.map(process_fn, current_cluster_ids),\n                    total=len(current_cluster_ids),\n                )\n            )\n\n        current_result_df = pd.DataFrame(responses)\n        clusters_df = clusters_df.merge(current_result_df, on=[current_columns.id])\n    return clusters_df\n\n\nclass LabellingFromat(BaseModel):\n    \"\"\"ラベリング結果のフォーマットを定義する\"\"\"\n\n    label: str = Field(..., description=\"クラスタのラベル名\")\n    description: str = Field(..., description=\"クラスタの説明文\")\n\n\ndef process_merge_labelling(\n    target_cluster_id: str,\n    result_df: pd.DataFrame,\n    current_columns: ClusterColumns,\n    previous_columns: ClusterColumns,\n    config,\n):\n    \"\"\"個別のクラスタに対してマージラベリングを実行する\n\n    Args:\n        target_cluster_id: 処理対象のクラスタID\n        result_df: クラスタリング結果のDataFrame\n        current_columns: 現在のレベルのカラム情報\n        previous_columns: 前のレベルのカラム情報\n        config: 設定情報を含む辞書\n\n    Returns:\n        マージラベリング結果を含む辞書\n    \"\"\"\n\n    def filter_previous_values(df: pd.DataFrame, previous_columns: ClusterColumns) -> list[ClusterValues]:\n        \"\"\"前のレベルのクラスタ情報を取得する\"\"\"\n        previous_records = df[df[current_columns.id] == target_cluster_id][\n            [previous_columns.label, previous_columns.description]\n        ].drop_duplicates()\n        previous_values = [\n            ClusterValues(\n                label=row[previous_columns.label],\n                description=row[previous_columns.description],\n            )\n            for _, row in previous_records.iterrows()\n        ]\n        return previous_values\n\n    previous_values = filter_previous_values(result_df, previous_columns)\n    if len(previous_values) == 1:\n        return {\n            current_columns.id: target_cluster_id,\n            current_columns.label: previous_values[0].label,\n            current_columns.description: previous_values[0].description,\n        }\n    elif len(previous_values) == 0:\n        raise ValueError(f\"クラスタ {target_cluster_id} には前のレベルのクラスタが存在しません。\")\n\n    current_cluster_data = result_df[result_df[current_columns.id] == target_cluster_id]\n    sampling_num = min(\n        config[\"hierarchical_merge_labelling\"][\"sampling_num\"],\n        len(current_cluster_data),\n    )\n    sampled_data = current_cluster_data.sample(sampling_num)\n    sampled_argument_text = \"\\n\".join(sampled_data[\"argument\"].values)\n    cluster_text = \"\\n\".join([value.to_prompt_text() for value in previous_values])\n    messages = [\n        {\"role\": \"system\", \"content\": config[\"hierarchical_merge_labelling\"][\"prompt\"]},\n        {\n            \"role\": \"user\",\n            \"content\": \"クラスタラベル\\n\" + cluster_text + \"\\n\" + \"クラスタの意見\\n\" + sampled_argument_text,\n        },\n    ]\n    try:\n        response_text, token_input, token_output, token_total = request_to_chat_ai(\n            messages=messages,\n            model=config[\"hierarchical_merge_labelling\"][\"model\"],\n            json_schema=LabellingFromat,\n            provider=config[\"provider\"],\n            local_llm_address=config.get(\"local_llm_address\"),\n        )\n\n        config[\"total_token_usage\"] = config.get(\"total_token_usage\", 0) + token_total\n        config[\"token_usage_input\"] = config.get(\"token_usage_input\", 0) + token_input\n        config[\"token_usage_output\"] = config.get(\"token_usage_output\", 0) + token_output\n        print(f\"Merge labelling: input={token_input}, output={token_output}, total={token_total} tokens\")\n\n        response_json = json.loads(response_text) if isinstance(response_text, str) else response_text\n        return {\n            current_columns.id: target_cluster_id,\n            current_columns.label: response_json.get(\"label\", \"エラーでラベル名が取得できませんでした\"),\n            current_columns.description: response_json.get(\"description\", \"エラーで解説が取得できませんでした\"),\n        }\n    except Exception as e:\n        print(f\"エラーが発生しました: {e}\")\n        return {\n            current_columns.id: target_cluster_id,\n            current_columns.label: \"エラーでラベル名が取得できませんでした\",\n            current_columns.description: \"エラーで解説が取得できませんでした\",\n        }\n\n\ndef calculate_cluster_density(melted_df: pd.DataFrame, config: dict):\n    \"\"\"クラスタ内の密度計算\"\"\"\n    hierarchical_cluster_df = pd.read_csv(f\"outputs/{config['output_dir']}/hierarchical_clusters.csv\")\n\n    densities = []\n    for level, c_id in zip(melted_df[\"level\"], melted_df[\"id\"], strict=False):\n        cluster_embeds = hierarchical_cluster_df[hierarchical_cluster_df[f\"cluster-level-{level}-id\"] == c_id][\n            [\"x\", \"y\"]\n        ].values\n        density = calculate_density(cluster_embeds)\n        densities.append(density)\n\n    # 密度のランクを計算\n    melted_df[\"density\"] = densities\n    melted_df[\"density_rank\"] = melted_df.groupby(\"level\")[\"density\"].rank(ascending=False, method=\"first\")\n    melted_df[\"density_rank_percentile\"] = melted_df.groupby(\"level\")[\"density_rank\"].transform(lambda x: x / len(x))\n    return melted_df\n\n\ndef calculate_density(embeds: np.ndarray):\n    \"\"\"平均距離に基づいて密度を計算\"\"\"\n    center = np.mean(embeds, axis=0)\n    distances = np.linalg.norm(embeds - center, axis=1)\n    avg_distance = np.mean(distances)\n    density = 1 / (avg_distance + 1e-10)\n    return density\n",
      "model": "gpt-4o-mini"
    },
    "hierarchical_overview": {
      "prompt": "/system \n\nあなたはシンクタンクで働く専門のリサーチアシスタントです。\nチームは特定のテーマに関してパブリック・コンサルテーションを実施し、異なる選択肢の意見グループを分析し始めています。\nこれから意見グループのリストとその簡単な分析が提供されます。\nあなたの仕事は、調査結果の簡潔な要約を返すことです。要約は非常に簡潔に（最大で1段落、最大4文）まとめ、無意味な言葉を避けてください。\n出力は日本語で行ってください。\n",
      "source_code": "\"\"\"Create summaries for the clusters.\"\"\"\n\nimport json\nimport re\n\nimport pandas as pd\nfrom pydantic import BaseModel, Field\n\nfrom services.llm import request_to_chat_ai\n\n\nclass OverviewResponse(BaseModel):\n    summary: str = Field(..., description=\"クラスターの全体的な要約\")\n\n\ndef hierarchical_overview(config):\n    dataset = config[\"output_dir\"]\n    path = f\"outputs/{dataset}/hierarchical_overview.txt\"\n\n    hierarchical_label_df = pd.read_csv(f\"outputs/{dataset}/hierarchical_merge_labels.csv\")\n\n    prompt = config[\"hierarchical_overview\"][\"prompt\"]\n    model = config[\"hierarchical_overview\"][\"model\"]\n\n    # TODO: level1で固定にしているが、設定で変えられるようにする\n    target_level = 1\n    target_records = hierarchical_label_df[hierarchical_label_df[\"level\"] == target_level]\n    ids = target_records[\"id\"].to_list()\n    labels = target_records[\"label\"].to_list()\n    descriptions = target_records[\"description\"].to_list()\n    target_records.set_index(\"id\", inplace=True)\n\n    input_text = \"\"\n    for i, _ in enumerate(ids):\n        input_text += f\"# Cluster {i}/{len(ids)}: {labels[i]}\\n\\n\"\n        input_text += descriptions[i] + \"\\n\\n\"\n\n    messages = [{\"role\": \"system\", \"content\": prompt}, {\"role\": \"user\", \"content\": input_text}]\n    response_text, token_input, token_output, token_total = request_to_chat_ai(\n        messages=messages,\n        model=model,\n        provider=config[\"provider\"],\n        local_llm_address=config.get(\"local_llm_address\"),\n        json_schema=OverviewResponse,\n    )\n\n    # トークン使用量を累積\n    config[\"total_token_usage\"] = config.get(\"total_token_usage\", 0) + token_total\n    config[\"token_usage_input\"] = config.get(\"token_usage_input\", 0) + token_input\n    config[\"token_usage_output\"] = config.get(\"token_usage_output\", 0) + token_output\n    print(f\"Hierarchical overview: input={token_input}, output={token_output}, total={token_total} tokens\")\n\n    try:\n        # structured outputとしてパースできるなら処理する\n        if isinstance(response_text, dict):\n            parsed_response = response_text\n        else:\n            parsed_response = json.loads(response_text)\n\n        with open(path, \"w\") as file:\n            file.write(parsed_response[\"summary\"])\n\n    except Exception:\n        # thinkタグが出力されるReasoningモデル用に、thinkタグを除去する\n        thinking_removed = re.sub(\n            r\"<think\\b[^>]*>.*?</think>\",\n            \"\",\n            response_text,\n            flags=re.DOTALL,\n        )\n\n        with open(path, \"w\") as file:\n            file.write(thinking_removed)\n",
      "model": "gpt-4o-mini"
    },
    "hierarchical_aggregation": {
      "sampling_num": 30,
      "hidden_properties": {},
      "source_code": "\"\"\"Generate a convenient JSON output file.\"\"\"\n\nimport json\nfrom collections import defaultdict\nfrom pathlib import Path\nfrom typing import Any, TypedDict\n\nimport numpy as np\nimport pandas as pd\n\nROOT_DIR = Path(__file__).parent.parent.parent.parent\nCONFIG_DIR = ROOT_DIR / \"scatter\" / \"pipeline\" / \"configs\"\nPIPELINE_DIR = ROOT_DIR / \"broadlistening\" / \"pipeline\"\n\n\ndef json_serialize_numpy(obj: Any) -> Any:\n    \"\"\"\n    Recursively convert NumPy data types to native Python types for JSON serialization.\n\n    Args:\n        obj: Any Python object which might contain NumPy data types\n\n    Returns:\n        The same object structure with NumPy types converted to Python native types\n    \"\"\"\n    if isinstance(obj, np.integer):\n        return int(obj)\n    elif isinstance(obj, np.floating):\n        return float(obj)\n    elif isinstance(obj, np.ndarray):\n        return obj.tolist()\n    elif isinstance(obj, dict):\n        return {k: json_serialize_numpy(v) for k, v in obj.items()}\n    elif isinstance(obj, list):\n        return [json_serialize_numpy(item) for item in obj]\n    elif isinstance(obj, tuple):\n        return tuple(json_serialize_numpy(item) for item in obj)\n    else:\n        return obj\n\n\nclass Argument(TypedDict):\n    arg_id: str\n    argument: str\n    comment_id: str\n    x: float\n    y: float\n    p: float\n    cluster_ids: list[str]\n    attributes: dict[str, str] | None\n    url: str | None\n\n\nclass Cluster(TypedDict):\n    level: int\n    id: str\n    label: str\n    takeaway: str\n    value: int\n    parent: str\n    density_rank_percentile: float | None\n\n\ndef hierarchical_aggregation(config) -> bool:\n    try:\n        path = f\"outputs/{config['output_dir']}/hierarchical_result.json\"\n        results = {\n            \"arguments\": [],\n            \"clusters\": [],\n            \"comments\": {},\n            \"propertyMap\": {},\n            \"translations\": {},\n            \"overview\": \"\",\n            \"config\": config,\n        }\n\n        arguments = pd.read_csv(f\"outputs/{config['output_dir']}/args.csv\")\n        arguments.set_index(\"arg-id\", inplace=True)\n        arg_num = len(arguments)\n        relation_df = pd.read_csv(f\"outputs/{config['output_dir']}/relations.csv\")\n        comments = pd.read_csv(f\"inputs/{config['input']}.csv\")\n        clusters = pd.read_csv(f\"outputs/{config['output_dir']}/hierarchical_clusters.csv\")\n        labels = pd.read_csv(f\"outputs/{config['output_dir']}/hierarchical_merge_labels.csv\")\n\n        hidden_properties_map: dict[str, list[str]] = config[\"hierarchical_aggregation\"][\"hidden_properties\"]\n\n        results[\"arguments\"] = _build_arguments(clusters, comments, relation_df, config)\n        results[\"clusters\"] = _build_cluster_value(labels, arg_num)\n\n        # results[\"comments\"] = _build_comments_value(\n        #     comments, arguments, hidden_properties_map\n        # )\n        results[\"comment_num\"] = len(comments)\n        results[\"translations\"] = _build_translations(config)\n        # 属性情報のカラムは、元データに対して指定したカラムとclassificationするカテゴリを合わせたもの\n        results[\"propertyMap\"] = _build_property_map(arguments, comments, hidden_properties_map, config)\n\n        with open(f\"outputs/{config['output_dir']}/hierarchical_overview.txt\") as f:\n            overview = f.read()\n        print(\"overview\")\n        print(overview)\n        results[\"overview\"] = overview\n\n        # Convert non-serializable NumPy types to native Python types\n        results = json_serialize_numpy(results)\n\n        with open(path, \"w\") as file:\n            json.dump(results, file, indent=2, ensure_ascii=False)\n        # TODO: サンプリングロジックを実装したいが、現状は全件抽出\n        create_custom_intro(config)\n        if config[\"is_pubcom\"]:\n            add_original_comments(labels, arguments, relation_df, clusters, config)\n        return True\n    except Exception as e:\n        print(\"error\")\n        print(e)\n        return False\n\n\ndef create_custom_intro(config):\n    dataset = config[\"output_dir\"]\n    args_path = PIPELINE_DIR / f\"outputs/{dataset}/args.csv\"\n    comments = pd.read_csv(PIPELINE_DIR / f\"inputs/{config['input']}.csv\")\n    result_path = PIPELINE_DIR / f\"outputs/{dataset}/hierarchical_result.json\"\n\n    input_count = len(comments)\n    args_count = len(pd.read_csv(args_path))\n    processed_num = min(input_count, config[\"extraction\"][\"limit\"])\n\n    print(f\"Input count: {input_count}\")\n    print(f\"Args count: {args_count}\")\n\n    # LLMプロバイダーとモデル名の判定\n    def get_llm_provider_display():\n        # configからプロバイダー情報を取得（優先）\n        provider = config.get(\"provider\", \"openai\")\n        model = config.get(\"model\", \"unknown\")\n\n        # プロバイダー名をマッピング\n        provider_names = {\n            \"openai\": \"OpenAI API\",\n            \"azure\": \"Azure OpenAI API\",\n            \"openrouter\": \"OpenRouter API\",\n            \"local\": \"Local LLM\",\n        }\n\n        provider_name = provider_names.get(provider, f\"{provider} API\")\n        return f\"{provider_name} ({model})\"\n\n    llm_provider = get_llm_provider_display()\n\n    base_custom_intro = \"\"\"{intro}\n分析対象となったデータの件数は{processed_num}件で、これらのデータに対して{llm_provider}を用いて{args_count}件の意見（議論）を抽出し、クラスタリングを行った。\n\"\"\"\n\n    intro = config[\"intro\"]\n    custom_intro = base_custom_intro.format(\n        intro=intro, processed_num=processed_num, args_count=args_count, llm_provider=llm_provider\n    )\n\n    with open(result_path) as f:\n        result = json.load(f)\n    result[\"config\"][\"intro\"] = custom_intro\n    with open(result_path, \"w\") as f:\n        json.dump(result, f, indent=2, ensure_ascii=False)\n\n\ndef add_original_comments(labels, arguments, relation_df, clusters, config):\n    # 大カテゴリ（cluster-level-1）に該当するラベルだけ抽出\n    labels_lv1 = labels[labels[\"level\"] == 1][[\"id\", \"label\"]].rename(\n        columns={\"id\": \"cluster-level-1-id\", \"label\": \"category_label\"}\n    )\n\n    # arguments と clusters をマージ（カテゴリ情報付与）\n    merged = arguments.merge(clusters[[\"arg-id\", \"cluster-level-1-id\"]], on=\"arg-id\").merge(\n        labels_lv1, on=\"cluster-level-1-id\", how=\"left\"\n    )\n\n    # relation_df と結合\n    merged = merged.merge(relation_df, on=\"arg-id\", how=\"left\")\n\n    # 元コメント取得\n    comments = pd.read_csv(PIPELINE_DIR / f\"inputs/{config['input']}.csv\")\n    comments[\"comment-id\"] = comments[\"comment-id\"].astype(str)\n    merged[\"comment-id\"] = merged[\"comment-id\"].astype(str)\n\n    # 元コメント本文などとマージ\n    final_df = merged.merge(comments, on=\"comment-id\", how=\"left\")\n\n    # 必要カラムのみ整形\n    final_cols = [\"comment-id\", \"comment-body\", \"arg-id\", \"argument\", \"cluster-level-1-id\", \"category_label\"]\n\n    # 基本カラム\n    for col in [\"x\", \"y\", \"source\", \"url\"]:\n        if col in comments.columns:\n            final_cols.append(col)\n\n    # 属性カラムを追加\n    attribute_columns = []\n    for col in comments.columns:\n        # attributeプレフィックスが付いたカラムを探す\n        if col.startswith(\"attribute_\"):\n            attribute_columns.append(col)\n            final_cols.append(col)\n\n    print(f\"属性カラム検出: {attribute_columns}\")\n\n    # 必要なカラムだけ選択\n    final_df = final_df[final_cols]\n    final_df = final_df.rename(\n        columns={\n            \"cluster-level-1-id\": \"category_id\",\n            \"category_label\": \"category\",\n            \"arg-id\": \"arg_id\",\n            \"argument\": \"argument\",\n            \"comment-body\": \"original-comment\",\n        }\n    )\n\n    # 保存\n    final_df.to_csv(PIPELINE_DIR / f\"outputs/{config['output_dir']}/final_result_with_comments.csv\", index=False)\n\n\ndef _build_arguments(\n    clusters: pd.DataFrame, comments: pd.DataFrame, relation_df: pd.DataFrame, config: dict\n) -> list[Argument]:\n    \"\"\"\n    Build the arguments list including attribute information from original comments\n\n    Args:\n        clusters: DataFrame containing cluster information for each argument\n        comments: DataFrame containing original comments with attribute columns\n        relation_df: DataFrame relating arguments to original comments\n        config: Configuration dictionary containing enable_source_link setting\n    \"\"\"\n    cluster_columns = [col for col in clusters.columns if col.startswith(\"cluster-level-\") and \"id\" in col]\n\n    # Prepare for merging with original comments to get attributes\n    comments_copy = comments.copy()\n    comments_copy[\"comment-id\"] = comments_copy[\"comment-id\"].astype(str)\n\n    # Get argument to comment mapping\n    arg_comment_map = {}\n    if \"comment-id\" in relation_df.columns:\n        relation_df[\"comment-id\"] = relation_df[\"comment-id\"].astype(str)\n        arg_comment_map = dict(zip(relation_df[\"arg-id\"], relation_df[\"comment-id\"], strict=False))\n\n    # Find attribute columns in comments dataframe\n    attribute_columns = [col for col in comments.columns if col.startswith(\"attribute_\")]\n    print(f\"属性カラム検出: {attribute_columns}\")\n\n    arguments: list[Argument] = []\n    for _, row in clusters.iterrows():\n        cluster_ids = [\"0\"]\n        for cluster_column in cluster_columns:\n            cluster_ids.append(str(row[cluster_column]))  # Convert to string to ensure serializable\n\n        # Create base argument\n        argument: Argument = {\n            \"arg_id\": str(row[\"arg-id\"]),  # Convert to string to ensure serializable\n            \"argument\": str(row[\"argument\"]),\n            \"x\": float(row[\"x\"]),  # Convert to native float\n            \"y\": float(row[\"y\"]),  # Convert to native float\n            \"p\": 0,  # NOTE: 一旦全部0でいれる\n            \"cluster_ids\": cluster_ids,\n            \"attributes\": None,\n            \"url\": None,\n        }\n\n        # Add attributes and URL if available\n        if row[\"arg-id\"] in arg_comment_map:\n            comment_id = arg_comment_map[row[\"arg-id\"]]\n            comment_rows = comments_copy[comments_copy[\"comment-id\"] == comment_id]\n\n            if not comment_rows.empty:\n                comment_row = comment_rows.iloc[0]\n\n                # Add URL if available and enabled\n                if config.get(\"enable_source_link\", False) and \"url\" in comment_row and comment_row[\"url\"] is not None:\n                    argument[\"url\"] = str(comment_row[\"url\"])\n\n                # Add attributes if available\n                if attribute_columns:\n                    attributes = {}\n                    for attr_col in attribute_columns:\n                        # Remove \"attribute_\" prefix for cleaner attribute names\n                        attr_name = attr_col[len(\"attribute_\") :]\n                        # Convert potential numpy types to Python native types\n                        attr_value = comment_row.get(attr_col, None)\n                        if attr_value is not None:\n                            if isinstance(attr_value, np.integer):\n                                attr_value = int(attr_value)\n                            elif isinstance(attr_value, np.floating):\n                                attr_value = float(attr_value)\n                            elif isinstance(attr_value, np.ndarray):\n                                attr_value = attr_value.tolist()\n                        attributes[attr_name] = attr_value\n\n                    # Only add non-empty attributes\n                    if any(v is not None for v in attributes.values()):\n                        argument[\"attributes\"] = attributes\n\n        arguments.append(argument)\n    return arguments\n\n\ndef _build_cluster_value(melted_labels: pd.DataFrame, total_num: int) -> list[Cluster]:\n    results: list[Cluster] = [\n        Cluster(\n            level=0,\n            id=\"0\",\n            label=\"全体\",\n            takeaway=\"\",\n            value=int(total_num),  # Convert to native int\n            parent=\"\",\n            density_rank_percentile=0,\n        )\n    ]\n\n    for _, melted_label in melted_labels.iterrows():\n        # Convert potential NumPy types to native Python types\n        level = (\n            int(melted_label[\"level\"]) if isinstance(melted_label[\"level\"], int | np.integer) else melted_label[\"level\"]\n        )\n        cluster_id = str(melted_label[\"id\"])\n        label = str(melted_label[\"label\"])\n        takeaway = str(melted_label[\"description\"])\n        value = (\n            int(melted_label[\"value\"]) if isinstance(melted_label[\"value\"], int | np.integer) else melted_label[\"value\"]\n        )\n        parent = str(melted_label.get(\"parent\", \"全体\"))\n\n        # Handle density_rank_percentile which might be None or a numeric value\n        density_rank = melted_label.get(\"density_rank_percentile\")\n        if density_rank is not None:\n            if isinstance(density_rank, float | np.floating):\n                density_rank = float(density_rank)\n            elif isinstance(density_rank, int | np.integer):\n                density_rank = int(density_rank)\n\n        cluster_value = Cluster(\n            level=level,\n            id=cluster_id,\n            label=label,\n            takeaway=takeaway,\n            value=value,\n            parent=parent,\n            density_rank_percentile=density_rank,\n        )\n        results.append(cluster_value)\n    return results\n\n\ndef _build_comments_value(\n    comments: pd.DataFrame,\n    arguments: pd.DataFrame,\n    hidden_properties_map: dict[str, list[str]],\n):\n    comment_dict: dict[str, dict[str, str]] = {}\n    useful_comment_ids = set(arguments[\"comment-id\"].values)\n    for _, row in comments.iterrows():\n        id = row[\"comment-id\"]\n        if id in useful_comment_ids:\n            res = {\"comment\": row[\"comment-body\"]}\n            should_skip = any(row[prop] in hidden_values for prop, hidden_values in hidden_properties_map.items())\n            if should_skip:\n                continue\n            comment_dict[str(id)] = res\n\n    return comment_dict\n\n\ndef _build_translations(config):\n    languages = list(config.get(\"translation\", {}).get(\"languages\", []))\n    if len(languages) > 0:\n        with open(PIPELINE_DIR / f\"outputs/{config['output_dir']}/translations.json\") as f:\n            translations = f.read()\n        return json.loads(translations)\n    return {}\n\n\ndef _build_property_map(\n    arguments: pd.DataFrame, comments: pd.DataFrame, hidden_properties_map: dict[str, list[str]], config: dict\n) -> dict[str, dict[str, str]]:\n    property_columns = list(hidden_properties_map.keys()) + list(config[\"extraction\"][\"categories\"].keys())\n    property_map = defaultdict(dict)\n\n    # 指定された property_columns が arguments に存在するかチェック\n    missing_cols = [col for col in property_columns if col not in arguments.columns]\n    if missing_cols:\n        raise ValueError(\n            f\"指定されたカラム {missing_cols} が args.csv に存在しません。\"\n            \"設定ファイルaggregation / hidden_propertiesから該当カラムを取り除いてください。\"\n        )\n\n    for prop in property_columns:\n        for arg_id, row in arguments.iterrows():\n            # LLMによるcategory classificationがうまく行かず、NaNの場合はNoneにする\n            value = row[prop] if not pd.isna(row[prop]) else None\n\n            # Convert NumPy types to Python native types\n            if value is not None:\n                if isinstance(value, np.integer):\n                    value = int(value)\n                elif isinstance(value, np.floating):\n                    value = float(value)\n                elif isinstance(value, np.ndarray):\n                    value = value.tolist()\n                else:\n                    # Convert any other types to string to ensure serialization\n                    try:\n                        value = str(value)\n                    except Exception as e:\n                        print(f\"Error converting value to string: {e}\")\n                        value = None\n\n            # Make sure arg_id is string\n            str_arg_id = str(arg_id)\n            property_map[prop][str_arg_id] = value\n\n    return property_map\n"
    },
    "enable_source_link": false,
    "output_dir": "adachi",
    "skip-interaction": true,
    "without-html": true,
    "embedding": {
      "model": "text-embedding-3-small",
      "source_code": "import pandas as pd\nfrom tqdm import tqdm\n\nfrom services.llm import request_to_embed\n\n\ndef embedding(config):\n    model = config[\"embedding\"][\"model\"]\n    is_embedded_at_local = config[\"is_embedded_at_local\"]\n    # print(\"start embedding\")\n    # print(f\"embedding model: {model}, is_embedded_at_local: {is_embedded_at_local}\")\n\n    dataset = config[\"output_dir\"]\n    path = f\"outputs/{dataset}/embeddings.pkl\"\n    arguments = pd.read_csv(f\"outputs/{dataset}/args.csv\", usecols=[\"arg-id\", \"argument\"])\n    embeddings = []\n    batch_size = 1000\n    for i in tqdm(range(0, len(arguments), batch_size)):\n        args = arguments[\"argument\"].tolist()[i : i + batch_size]\n        embeds = request_to_embed(args, model, is_embedded_at_local, config[\"provider\"])\n        embeddings.extend(embeds)\n    df = pd.DataFrame([{\"arg-id\": arguments.iloc[i][\"arg-id\"], \"embedding\": e} for i, e in enumerate(embeddings)])\n    df.to_pickle(path)\n"
    },
    "hierarchical_visualization": {
      "replacements": [],
      "source_code": "import subprocess\n\n\ndef hierarchical_visualization(config):\n    output_dir = config[\"output_dir\"]\n    cwd = \"../report\"\n    command = f\"REPORT={output_dir} npm run build\"\n\n    try:\n        process = subprocess.Popen(\n            command,\n            shell=True,\n            cwd=cwd,\n            stdout=subprocess.PIPE,\n            stderr=subprocess.PIPE,\n            universal_newlines=True,\n        )\n        while True:\n            output_line = process.stdout.readline()\n            if output_line == \"\" and process.poll() is not None:\n                break\n            if output_line:\n                print(output_line.strip())\n        process.wait()\n        errors = process.stderr.read()\n        if errors:\n            print(\"Errors:\")\n            print(errors)\n    except subprocess.CalledProcessError as e:\n        print(\"Error: \", e)\n"
    },
    "plan": [
      {
        "step": "extraction",
        "run": true,
        "reason": "not trace of previous run"
      },
      {
        "step": "embedding",
        "run": true,
        "reason": "not trace of previous run"
      },
      {
        "step": "hierarchical_clustering",
        "run": true,
        "reason": "not trace of previous run"
      },
      {
        "step": "hierarchical_initial_labelling",
        "run": true,
        "reason": "not trace of previous run"
      },
      {
        "step": "hierarchical_merge_labelling",
        "run": true,
        "reason": "not trace of previous run"
      },
      {
        "step": "hierarchical_overview",
        "run": true,
        "reason": "not trace of previous run"
      },
      {
        "step": "hierarchical_aggregation",
        "run": true,
        "reason": "not trace of previous run"
      },
      {
        "step": "hierarchical_visualization",
        "run": false,
        "reason": "skipping html output"
      }
    ],
    "status": "running",
    "start_time": "2025-08-23T05:14:45.579447",
    "completed_jobs": [
      {
        "step": "extraction",
        "completed": "2025-08-23T05:14:50.114538",
        "duration": 4.530973,
        "params": {
          "prompt": "あなたは専門的なリサーチアシスタントです。与えられたテキストから、意見を抽出して整理してください。\n\n# 指示\n* 入出力の例に記載したような形式で文字列のリストを返してください\n  * 必要な場合は2つの別個の意見に分割してください。多くの場合は1つの議論にまとめる方が望ましいです。\n* 整理した意見は日本語で出力してください\n\n## 入出力の例\n/human\n\nAIテクノロジーは、そのライフサイクル全体における環境負荷を削減することに焦点を当てて開発されるべきです。\n\n/ai\n\n{\n  \"extractedOpinionList\": [\n    \"AIテクノロジーは、そのライフサイクル全体における環境負荷を削減することに焦点を当てて開発されるべきです。\"\n  ]\n}\n\n/human\n\nAIの能力、限界、倫理的考慮事項について、市民を教育する必要がある。また、教育できる人材を養成する必要がある。\n\n/ai\n\n{\n  \"extractedOpinionList\": [\n    \"AIの能力、限界、倫理的考慮事項について、市民を教育すべき\",\n    \"AIに関する教育をできる人材を養成すべき\"\n  ]\n}\n\n/human\n\nAIはエネルギーグリッドを最適化し、無駄や炭素排出を削減できます。\n\n/ai\n\n{\n  \"extractedOpinionList\": [\n    \"AIはエネルギーグリッドを最適化して炭素排出を削減できる\"\n  ]\n}\n",
          "workers": 30,
          "limit": 20,
          "properties": [],
          "categories": {},
          "category_batch_size": 5,
          "source_code": "import concurrent.futures\nimport json\nimport logging\nimport re\n\nimport pandas as pd\nfrom pydantic import BaseModel, Field\nfrom tqdm import tqdm\n\nfrom services.category_classification import classify_args\nfrom services.llm import request_to_chat_ai\nfrom services.parse_json_list import parse_extraction_response\nfrom utils import update_progress\n\nCOMMA_AND_SPACE_AND_RIGHT_BRACKET = re.compile(r\",\\s*(\\])\")\n\n\nclass ExtractionResponse(BaseModel):\n    extractedOpinionList: list[str] = Field(..., description=\"抽出した意見のリスト\")\n\n\ndef _validate_property_columns(property_columns: list[str], comments: pd.DataFrame) -> None:\n    if not all(property in comments.columns for property in property_columns):\n        raise ValueError(f\"Properties {property_columns} not found in comments. Columns are {comments.columns}\")\n\n\ndef extraction(config):\n    dataset = config[\"output_dir\"]\n    path = f\"outputs/{dataset}/args.csv\"\n    model = config[\"extraction\"][\"model\"]\n    prompt = config[\"extraction\"][\"prompt\"]\n    workers = config[\"extraction\"][\"workers\"]\n    limit = config[\"extraction\"][\"limit\"]\n    property_columns = config[\"extraction\"][\"properties\"]\n\n    if \"provider\" not in config:\n        raise RuntimeError(\"provider is not set\")\n    provider = config[\"provider\"]\n\n    # カラム名だけを読み込み、必要なカラムが含まれているか確認する\n    comments = pd.read_csv(f\"inputs/{config['input']}.csv\", nrows=0)\n    _validate_property_columns(property_columns, comments)\n    # エラーが出なかった場合、すべての行を読み込む\n    comments = pd.read_csv(\n        f\"inputs/{config['input']}.csv\", usecols=[\"comment-id\", \"comment-body\"] + config[\"extraction\"][\"properties\"]\n    )\n    comment_ids = (comments[\"comment-id\"].values)[:limit]\n    comments.set_index(\"comment-id\", inplace=True)\n    results = pd.DataFrame()\n    update_progress(config, total=len(comment_ids))\n\n    argument_map = {}\n    relation_rows = []\n\n    for i in tqdm(range(0, len(comment_ids), workers)):\n        batch = comment_ids[i : i + workers]\n        batch_inputs = [comments.loc[id][\"comment-body\"] for id in batch]\n        batch_results = extract_batch(\n            batch_inputs, prompt, model, workers, provider, config.get(\"local_llm_address\"), config\n        )\n\n        for comment_id, extracted_args in zip(batch, batch_results, strict=False):\n            for j, arg in enumerate(extracted_args):\n                if arg not in argument_map:\n                    # argumentテーブルに追加\n                    arg_id = f\"A{comment_id}_{j}\"\n                    argument = arg\n                    argument_map[arg] = {\n                        \"arg-id\": arg_id,\n                        \"argument\": argument,\n                    }\n                else:\n                    arg_id = argument_map[arg][\"arg-id\"]\n\n                # relationテーブルにcommentとargの関係を追加\n                relation_row = {\n                    \"arg-id\": arg_id,\n                    \"comment-id\": comment_id,\n                }\n                relation_rows.append(relation_row)\n\n        update_progress(config, incr=len(batch))\n\n    # DataFrame化\n    results = pd.DataFrame(argument_map.values())\n    relation_df = pd.DataFrame(relation_rows)\n\n    if results.empty:\n        raise RuntimeError(\"result is empty, maybe bad prompt\")\n\n    classification_categories = config[\"extraction\"][\"categories\"]\n    if classification_categories:\n        results = classify_args(results, config, workers)\n\n    results.to_csv(path, index=False)\n    # comment-idとarg-idの関係を保存\n    relation_df.to_csv(f\"outputs/{dataset}/relations.csv\", index=False)\n\n\nlogging.basicConfig(level=logging.ERROR)\n\n\ndef extract_batch(batch, prompt, model, workers, provider=\"openai\", local_llm_address=None, config=None):\n    with concurrent.futures.ThreadPoolExecutor(max_workers=workers) as executor:\n        futures_with_index = [\n            (i, executor.submit(extract_arguments, input, prompt, model, provider, local_llm_address))\n            for i, input in enumerate(batch)\n        ]\n\n        done, not_done = concurrent.futures.wait([f for _, f in futures_with_index], timeout=30)\n        results = [[] for _ in range(len(batch))]\n        total_token_input = 0\n        total_token_output = 0\n        total_token_usage = 0\n\n        for _, future in futures_with_index:\n            if future in not_done and not future.cancelled():\n                future.cancel()\n\n        for i, future in futures_with_index:\n            if future in done:\n                try:\n                    result = future.result()\n                    if isinstance(result, tuple) and len(result) == 4:\n                        items, token_input, token_output, token_total = result\n                        results[i] = items\n                        total_token_input += token_input\n                        total_token_output += token_output\n                        total_token_usage += token_total\n                    else:\n                        results[i] = result\n                except Exception as e:\n                    logging.error(f\"Task {future} failed with error: {e}\")\n                    results[i] = []\n\n        if config is not None:\n            config[\"total_token_usage\"] = config.get(\"total_token_usage\", 0) + total_token_usage\n            config[\"token_usage_input\"] = config.get(\"token_usage_input\", 0) + total_token_input\n            config[\"token_usage_output\"] = config.get(\"token_usage_output\", 0) + total_token_output\n            print(\n                f\"Extraction batch: input={total_token_input}, output={total_token_output}, total={total_token_usage} tokens\"\n            )\n\n        return results\n\n\ndef extract_arguments(input, prompt, model, provider=\"openai\", local_llm_address=None):\n    messages = [\n        {\"role\": \"system\", \"content\": prompt},\n        {\"role\": \"user\", \"content\": input},\n    ]\n    try:\n        response, token_input, token_output, token_total = request_to_chat_ai(\n            messages=messages,\n            model=model,\n            is_json=False,\n            json_schema=ExtractionResponse,\n            provider=provider,\n            local_llm_address=local_llm_address,\n        )\n        items = parse_extraction_response(response)\n        items = list(filter(None, items))  # omit empty strings\n        return items, token_input, token_output, token_total\n    except json.decoder.JSONDecodeError as e:\n        print(\"JSON error:\", e)\n        print(\"Input was:\", input)\n        print(\"Response was:\", response)\n        print(\"Silently giving up on trying to generate valid list.\")\n        return []\n",
          "model": "gpt-4o-mini"
        },
        "token_usage": 11286
      },
      {
        "step": "embedding",
        "completed": "2025-08-23T05:14:51.119293",
        "duration": 1.000846,
        "params": {
          "model": "text-embedding-3-small",
          "source_code": "import pandas as pd\nfrom tqdm import tqdm\n\nfrom services.llm import request_to_embed\n\n\ndef embedding(config):\n    model = config[\"embedding\"][\"model\"]\n    is_embedded_at_local = config[\"is_embedded_at_local\"]\n    # print(\"start embedding\")\n    # print(f\"embedding model: {model}, is_embedded_at_local: {is_embedded_at_local}\")\n\n    dataset = config[\"output_dir\"]\n    path = f\"outputs/{dataset}/embeddings.pkl\"\n    arguments = pd.read_csv(f\"outputs/{dataset}/args.csv\", usecols=[\"arg-id\", \"argument\"])\n    embeddings = []\n    batch_size = 1000\n    for i in tqdm(range(0, len(arguments), batch_size)):\n        args = arguments[\"argument\"].tolist()[i : i + batch_size]\n        embeds = request_to_embed(args, model, is_embedded_at_local, config[\"provider\"])\n        embeddings.extend(embeds)\n    df = pd.DataFrame([{\"arg-id\": arguments.iloc[i][\"arg-id\"], \"embedding\": e} for i, e in enumerate(embeddings)])\n    df.to_pickle(path)\n"
        },
        "token_usage": 0
      },
      {
        "step": "hierarchical_clustering",
        "completed": "2025-08-23T05:14:57.248891",
        "duration": 6.125376,
        "params": {
          "cluster_nums": [
            3,
            9
          ],
          "source_code": "\"\"\"Cluster the arguments using UMAP + HDBSCAN and GPT-4.\"\"\"\n\nfrom importlib import import_module\n\nimport numpy as np\nimport pandas as pd\nimport scipy.cluster.hierarchy as sch\nfrom sklearn.cluster import KMeans\n\n\ndef hierarchical_clustering(config):\n    UMAP = import_module(\"umap\").UMAP\n\n    dataset = config[\"output_dir\"]\n    path = f\"outputs/{dataset}/hierarchical_clusters.csv\"\n    arguments_df = pd.read_csv(f\"outputs/{dataset}/args.csv\", usecols=[\"arg-id\", \"argument\"])\n    embeddings_df = pd.read_pickle(f\"outputs/{dataset}/embeddings.pkl\")\n    embeddings_array = np.asarray(embeddings_df[\"embedding\"].values.tolist())\n    cluster_nums = config[\"hierarchical_clustering\"][\"cluster_nums\"]\n\n    n_samples = embeddings_array.shape[0]\n    # デフォルト設定は15\n    default_n_neighbors = 15\n\n    # テスト等サンプルが少なすぎる場合、n_neighborsの設定値を下げる\n    if n_samples <= default_n_neighbors:\n        n_neighbors = max(2, n_samples - 1)  # 最低2以上\n    else:\n        n_neighbors = default_n_neighbors\n\n    umap_model = UMAP(random_state=42, n_components=2, n_neighbors=n_neighbors)\n    # TODO 詳細エラーメッセージを加える\n    # 以下のエラーの場合、おそらく元の意見件数が少なすぎることが原因\n    # TypeError: Cannot use scipy.linalg.eigh for sparse A with k >= N. Use scipy.linalg.eigh(A.toarray()) or reduce k.\n    umap_embeds = umap_model.fit_transform(embeddings_array)\n\n    cluster_results = hierarchical_clustering_embeddings(\n        umap_embeds=umap_embeds,\n        cluster_nums=cluster_nums,\n    )\n    result_df = pd.DataFrame(\n        {\n            \"arg-id\": arguments_df[\"arg-id\"],\n            \"argument\": arguments_df[\"argument\"],\n            \"x\": umap_embeds[:, 0],\n            \"y\": umap_embeds[:, 1],\n        }\n    )\n\n    for cluster_level, final_labels in enumerate(cluster_results.values(), start=1):\n        result_df[f\"cluster-level-{cluster_level}-id\"] = [f\"{cluster_level}_{label}\" for label in final_labels]\n\n    result_df.to_csv(path, index=False)\n\n\ndef generate_cluster_count_list(min_clusters: int, max_clusters: int):\n    cluster_counts = []\n    current = min_clusters\n    cluster_counts.append(current)\n\n    if min_clusters == max_clusters:\n        return cluster_counts\n\n    while True:\n        next_double = current * 2\n        next_triple = current * 3\n\n        if next_double >= max_clusters:\n            if cluster_counts[-1] != max_clusters:\n                cluster_counts.append(max_clusters)\n            break\n\n        # 次の倍はまだ max_clusters に収まるが、3倍だと超える\n        # -> (次の倍は細かすぎるので)スキップして max_clusters に飛ぶ\n        if next_triple > max_clusters:\n            cluster_counts.append(max_clusters)\n            break\n\n        cluster_counts.append(next_double)\n        current = next_double\n\n    return cluster_counts\n\n\ndef merge_clusters_with_hierarchy(\n    cluster_centers: np.ndarray,\n    kmeans_labels: np.ndarray,\n    umap_array: np.ndarray,\n    n_cluster_cut: int,\n):\n    Z = sch.linkage(cluster_centers, method=\"ward\")\n    cluster_labels_merged = sch.fcluster(Z, t=n_cluster_cut, criterion=\"maxclust\")\n\n    n_samples = umap_array.shape[0]\n    final_labels = np.zeros(n_samples, dtype=int)\n\n    for i in range(n_samples):\n        original_label = kmeans_labels[i]\n        final_labels[i] = cluster_labels_merged[original_label]\n\n    return final_labels\n\n\ndef hierarchical_clustering_embeddings(\n    umap_embeds,\n    cluster_nums,\n):\n    # 最大分割数でクラスタリングを実施\n    print(\"start initial clustering\")\n    initial_cluster_num = cluster_nums[-1]\n    kmeans_model = KMeans(n_clusters=initial_cluster_num, random_state=42)\n    kmeans_model.fit(umap_embeds)\n    print(\"end initial clustering\")\n\n    results = {}\n    print(\"start hierarchical clustering\")\n    cluster_nums.sort()\n    print(cluster_nums)\n    for n_cluster_cut in cluster_nums[:-1]:\n        print(\"n_cluster_cut: \", n_cluster_cut)\n        final_labels = merge_clusters_with_hierarchy(\n            cluster_centers=kmeans_model.cluster_centers_,\n            kmeans_labels=kmeans_model.labels_,\n            umap_array=umap_embeds,\n            n_cluster_cut=n_cluster_cut,\n        )\n        results[n_cluster_cut] = final_labels\n\n    results[initial_cluster_num] = kmeans_model.labels_\n    print(\"end hierarchical clustering\")\n\n    return results\n"
        },
        "token_usage": 0
      },
      {
        "step": "hierarchical_initial_labelling",
        "completed": "2025-08-23T05:15:01.655066",
        "duration": 4.402003,
        "params": {
          "prompt": "あなたはKJ法が得意なデータ分析者です。userのinputはグループに集まったラベルです。なぜそのラベルが一つのグループであるか解説し、表札（label）をつけてください。\n表札については、グループ内の具体的な論点や特徴を反映した、具体性の高い名称を考案してください。\n出力はJSONとし、フォーマットは以下のサンプルを参考にしてください。\n\n\n# サンプルの入出力\n## 入力例\n- 手作業での意見分析は時間がかかりすぎる。AIで効率化できると嬉しい\n- 今のやり方だと分析に工数がかかりすぎるけど、AIならコストをかけずに分析できそう\n- AIが自動で意見を整理してくれると楽になって嬉しい\n\n\n## 出力例\n{\n    \"label\": \"AIによる業務効率の大幅向上とコスト効率化\",\n    \"description\": \"この意見グループは、従来の手作業による意見分析と比較して、AIによる自動化で分析プロセスが効率化され、作業時間の短縮や運用コストの効率化が実現される点に対する前向きな評価が中心です。\"\n}\n",
          "sampling_num": 30,
          "workers": 30,
          "source_code": "import json\nfrom concurrent.futures import ThreadPoolExecutor\nfrom functools import partial\nfrom typing import TypedDict\n\nimport pandas as pd\nfrom pydantic import BaseModel, Field\n\nfrom services.llm import request_to_chat_ai\n\n\nclass LabellingResult(TypedDict):\n    \"\"\"各クラスタのラベリング結果を表す型\"\"\"\n\n    cluster_id: str  # クラスタのID\n    label: str  # クラスタのラベル名\n    description: str  # クラスタの説明文\n\n\ndef hierarchical_initial_labelling(config: dict) -> None:\n    \"\"\"階層的クラスタリングの初期ラベリングを実行する\n\n    Args:\n        config: 設定情報を含む辞書\n            - output_dir: 出力ディレクトリ名\n            - hierarchical_initial_labelling: 初期ラベリングの設定\n                - sampling_num: サンプリング数\n                - prompt: LLMへのプロンプト\n                - model: 使用するLLMモデル名\n                - workers: 並列処理のワーカー数\n            - provider: LLMプロバイダー\n    \"\"\"\n    dataset = config[\"output_dir\"]\n    path = f\"outputs/{dataset}/hierarchical_initial_labels.csv\"\n    clusters_argument_df = pd.read_csv(f\"outputs/{dataset}/hierarchical_clusters.csv\")\n\n    cluster_id_columns = [col for col in clusters_argument_df.columns if col.startswith(\"cluster-level-\")]\n    initial_cluster_id_column = cluster_id_columns[-1]\n    sampling_num = config[\"hierarchical_initial_labelling\"][\"sampling_num\"]\n    initial_labelling_prompt = config[\"hierarchical_initial_labelling\"][\"prompt\"]\n    model = config[\"hierarchical_initial_labelling\"][\"model\"]\n    workers = config[\"hierarchical_initial_labelling\"][\"workers\"]\n\n    # トークン使用量を追跡するための変数を初期化\n    config[\"total_token_usage\"] = config.get(\"total_token_usage\", 0)\n\n    initial_label_df = initial_labelling(\n        initial_labelling_prompt,\n        clusters_argument_df,\n        sampling_num,\n        model,\n        workers,\n        config[\"provider\"],\n        config.get(\"local_llm_address\"),\n        config,  # configを渡して、トークン使用量を累積できるようにする\n    )\n    print(\"start initial labelling\")\n    initial_clusters_argument_df = clusters_argument_df.merge(\n        initial_label_df,\n        left_on=initial_cluster_id_column,\n        right_on=\"cluster_id\",\n        how=\"left\",\n    ).rename(\n        columns={\n            \"label\": f\"{initial_cluster_id_column.replace('-id', '')}-label\",\n            \"description\": f\"{initial_cluster_id_column.replace('-id', '')}-description\",\n        }\n    )\n    print(\"end initial labelling\")\n    initial_clusters_argument_df.to_csv(path, index=False)\n\n\ndef initial_labelling(\n    prompt: str,\n    clusters_df: pd.DataFrame,\n    sampling_num: int,\n    model: str,\n    workers: int,\n    provider: str = \"openai\",\n    local_llm_address: str | None = None,\n    config: dict | None = None,  # configを追加\n) -> pd.DataFrame:\n    \"\"\"各クラスタに対して初期ラベリングを実行する\n\n    Args:\n        prompt: LLMへのプロンプト\n        clusters_df: クラスタリング結果のDataFrame\n        sampling_num: 各クラスタからサンプリングする意見の数\n        model: 使用するLLMモデル名\n        workers: 並列処理のワーカー数\n        provider: LLMプロバイダー\n        local_llm_address: ローカルLLMのアドレス\n        config: 設定情報を含む辞書（トークン使用量の累積に使用）\n\n    Returns:\n        各クラスタのラベリング結果を含むDataFrame\n    \"\"\"\n    cluster_columns = [col for col in clusters_df.columns if col.startswith(\"cluster-level-\")]\n    initial_cluster_column = cluster_columns[-1]\n    cluster_ids = clusters_df[initial_cluster_column].unique()\n    process_func = partial(\n        process_initial_labelling,\n        df=clusters_df,\n        prompt=prompt,\n        sampling_num=sampling_num,\n        target_column=initial_cluster_column,\n        model=model,\n        provider=provider,\n        local_llm_address=local_llm_address,\n        config=config,  # configを渡す\n    )\n    with ThreadPoolExecutor(max_workers=workers) as executor:\n        results = list(executor.map(process_func, cluster_ids))\n    return pd.DataFrame(results)\n\n\nclass LabellingFromat(BaseModel):\n    \"\"\"ラベリング結果のフォーマットを定義する\"\"\"\n\n    label: str = Field(..., description=\"クラスタのラベル名\")\n    description: str = Field(..., description=\"クラスタの説明文\")\n\n\ndef process_initial_labelling(\n    cluster_id: str,\n    df: pd.DataFrame,\n    prompt: str,\n    sampling_num: int,\n    target_column: str,\n    model: str,\n    provider: str = \"openai\",\n    local_llm_address: str | None = None,\n    config: dict | None = None,  # configを追加\n) -> LabellingResult:\n    \"\"\"個別のクラスタに対してラベリングを実行する\n\n    Args:\n        cluster_id: 処理対象のクラスタID\n        df: クラスタリング結果のDataFrame\n        prompt: LLMへのプロンプト\n        sampling_num: サンプリングする意見の数\n        target_column: クラスタIDが格納されている列名\n        model: 使用するLLMモデル名\n        provider: LLMプロバイダー\n        local_llm_address: ローカルLLMのアドレス\n        config: 設定情報を含む辞書（トークン使用量の累積に使用）\n\n    Returns:\n        クラスタのラベリング結果\n    \"\"\"\n    cluster_data = df[df[target_column] == cluster_id]\n    sampling_num = min(sampling_num, len(cluster_data))\n    cluster = cluster_data.sample(sampling_num)\n    input = \"\\n\".join(cluster[\"argument\"].values)\n    messages = [\n        {\"role\": \"system\", \"content\": prompt},\n        {\"role\": \"user\", \"content\": input},\n    ]\n    try:\n        response_text, token_input, token_output, token_total = request_to_chat_ai(\n            messages=messages,\n            model=model,\n            provider=provider,\n            json_schema=LabellingFromat,\n            local_llm_address=local_llm_address,\n        )\n\n        # トークン使用量を累積（configが渡されている場合）\n        if config is not None:\n            config[\"total_token_usage\"] = config.get(\"total_token_usage\", 0) + token_total\n            config[\"token_usage_input\"] = config.get(\"token_usage_input\", 0) + token_input\n            config[\"token_usage_output\"] = config.get(\"token_usage_output\", 0) + token_output\n\n        response_json = json.loads(response_text) if isinstance(response_text, str) else response_text\n        return LabellingResult(\n            cluster_id=cluster_id,\n            label=response_json.get(\"label\", \"エラーでラベル名が取得できませんでした\"),\n            description=response_json.get(\"description\", \"エラーで解説が取得できませんでした\"),\n        )\n    except Exception as e:\n        print(e)\n        return LabellingResult(\n            cluster_id=cluster_id,\n            label=\"エラーでラベル名が取得できませんでした\",\n            description=\"エラーで解説が取得できませんでした\",\n        )\n",
          "model": "gpt-4o-mini"
        },
        "token_usage": 6620
      },
      {
        "step": "hierarchical_merge_labelling",
        "completed": "2025-08-23T05:15:04.560498",
        "duration": 2.900874,
        "params": {
          "prompt": "あなたはデータ分析のエキスパートです。\n現在、テキストデータの階層クラスタリングを行っています。\n下層のクラスタ（意見グループ）のタイトルと説明、およびそれらのクラスタが所属する上層のクラスタのテキストのサンプルを与えるので、上層のクラスタのタイトルと説明を作成してください。\n\n# 指示\n- 統合後のクラスタ名は、統合前のクラスタ名称をそのまま引用せず、内容に基づいた新たな名称にしてください。\n- タイトルには、具体的な事象・行動（例：地域ごとの迅速対応、復興計画の着実な進展、効果的な情報共有・地域協力など）を含めてください\n  - 可能な限り具体的な表現を用いるようにし、抽象的な表現は避けてください\n    - 「多様な意見」などの抽象的な表現は避けてください\n- 出力例に示したJSON形式で出力してください\n\n\n# サンプルの入出力\n## 入力例\n- 「顧客フィードバックの自動集約」: この意見グループは、SNSやオンラインレビューなどから集めた大量の意見をAIが瞬時に解析し、企業が市場のトレンドや顧客の要望を即時に把握できる点についての期待を示しています。\n- 「AIによる業務効率の大幅向上とコスト効率化」: この意見グループは、従来の手作業による意見分析と比較して、AIによる自動化で分析プロセスが効率化され、作業時間の短縮や運用コストの効率化が実現される点に対する前向きな評価が中心です。\n\n## 出力例\n{\n    \"label\": \"AI技術の導入による意見分析の効率化への期待\",\n    \"description\": \"大量の意見やフィードバックから迅速に洞察を抽出できるため、企業や自治体が消費者や市民の声を的確に把握し、戦略的な意思決定やサービス改善が可能になります。また、従来の手法と比べて作業負荷が軽減され、業務効率の向上やコスト削減といった実際の便益が得られると期待されています。\"\n}\n",
          "sampling_num": 30,
          "workers": 30,
          "source_code": "import json\nfrom concurrent.futures import ThreadPoolExecutor\nfrom dataclasses import dataclass\nfrom functools import partial\n\nimport numpy as np\nimport pandas as pd\nfrom pydantic import BaseModel, Field\nfrom tqdm import tqdm\n\nfrom services.llm import request_to_chat_ai\n\n\n@dataclass\nclass ClusterColumns:\n    \"\"\"同一階層のクラスター関連のカラム名を管理するクラス\"\"\"\n\n    id: str\n    label: str\n    description: str\n\n    @classmethod\n    def from_id_column(cls, id_column: str) -> \"ClusterColumns\":\n        \"\"\"ID列名から関連するカラム名を生成\"\"\"\n        return cls(\n            id=id_column,\n            label=id_column.replace(\"-id\", \"-label\"),\n            description=id_column.replace(\"-id\", \"-description\"),\n        )\n\n\n@dataclass\nclass ClusterValues:\n    \"\"\"対象クラスタのlabel/descriptionを管理するクラス\"\"\"\n\n    label: str\n    description: str\n\n    def to_prompt_text(self) -> str:\n        return f\"- {self.label}: {self.description}\"\n\n\ndef hierarchical_merge_labelling(config: dict) -> None:\n    \"\"\"階層的クラスタリングの結果に対してマージラベリングを実行する\n\n    Args:\n        config: 設定情報を含む辞書\n            - output_dir: 出力ディレクトリ名\n            - hierarchical_merge_labelling: マージラベリングの設定\n                - sampling_num: サンプリング数\n                - prompt: LLMへのプロンプト\n                - model: 使用するLLMモデル名\n                - workers: 並列処理のワーカー数\n            - provider: LLMプロバイダー\n    \"\"\"\n    dataset = config[\"output_dir\"]\n    merge_path = f\"outputs/{dataset}/hierarchical_merge_labels.csv\"\n    clusters_df = pd.read_csv(f\"outputs/{dataset}/hierarchical_initial_labels.csv\")\n\n    cluster_id_columns: list[str] = _filter_id_columns(clusters_df.columns)\n    # ボトムクラスタのラベル・説明とクラスタid付きの各argumentを入力し、各階層のクラスタラベル・説明を生成し、argumentに付けたdfを作成\n    merge_result_df = merge_labelling(\n        clusters_df=clusters_df,\n        cluster_id_columns=sorted(cluster_id_columns, reverse=True),\n        config=config,\n    )\n    # 上記のdfから各クラスタのlevel, id, label, description, valueを取得してdfを作成\n    melted_df = melt_cluster_data(merge_result_df)\n    # 上記のdfに親子関係を追加\n    parent_child_df = _build_parent_child_mapping(merge_result_df, cluster_id_columns)\n    melted_df = melted_df.merge(parent_child_df, on=[\"level\", \"id\"], how=\"left\")\n    density_df = calculate_cluster_density(melted_df, config)\n    density_df.to_csv(merge_path, index=False)\n\n\ndef _build_parent_child_mapping(df: pd.DataFrame, cluster_id_columns: list[str]):\n    \"\"\"クラスタ間の親子関係をマッピングする\n\n    Args:\n        df: クラスタリング結果のDataFrame\n        cluster_id_columns: クラスタIDのカラム名のリスト\n\n    Returns:\n        親子関係のマッピング情報を含むDataFrame\n    \"\"\"\n    results = []\n    top_cluster_column = cluster_id_columns[0]\n    top_cluster_values = df[top_cluster_column].unique()\n    for c in top_cluster_values:\n        results.append(\n            {\n                \"level\": 1,\n                \"id\": c,\n                \"parent\": \"0\",  # aggregationで追加する全体クラスタのid\n            }\n        )\n\n    for idx in range(len(cluster_id_columns) - 1):\n        current_column = cluster_id_columns[idx]\n        children_column = cluster_id_columns[idx + 1]\n        current_level = current_column.replace(\"-id\", \"\").replace(\"cluster-level-\", \"\")\n        # 現在のレベルのクラスタid\n        current_cluster_values = df[current_column].unique()\n        for current_id in current_cluster_values:\n            children_ids = df.loc[df[current_column] == current_id, children_column].unique()\n            for child_id in children_ids:\n                results.append(\n                    {\n                        \"level\": int(current_level) + 1,\n                        \"id\": child_id,\n                        \"parent\": current_id,\n                    }\n                )\n    return pd.DataFrame(results)\n\n\ndef _filter_id_columns(columns: list[str]) -> list[str]:\n    \"\"\"クラスタIDのカラム名をフィルタリングする\n\n    Args:\n        columns: 全カラム名のリスト\n\n    Returns:\n        クラスタIDのカラム名のリスト\n    \"\"\"\n    return [col for col in columns if col.startswith(\"cluster-level-\") and col.endswith(\"-id\")]\n\n\ndef melt_cluster_data(df: pd.DataFrame) -> pd.DataFrame:\n    \"\"\"クラスタデータを行形式に変換する\n\n    cluster-level-n-(id|label|description) を行形式 (level, id, label, description, value) にまとめる。\n    [cluster-level-n-id, cluster-level-n-label, cluster-level-n-description] を [level, id, label, description, value(件数)] に変換する。\n\n    Args:\n        df: クラスタリング結果のDataFrame\n\n    Returns:\n        行形式に変換されたDataFrame\n    \"\"\"\n    id_columns: list[str] = _filter_id_columns(df.columns)\n    levels: set[int] = {int(col.replace(\"cluster-level-\", \"\").replace(\"-id\", \"\")) for col in id_columns}\n    all_rows: list[dict] = []\n\n    # levelごとに各クラスタの出現件数を集計・縦持ちにする\n    for level in levels:\n        cluster_columns = ClusterColumns.from_id_column(f\"cluster-level-{level}-id\")\n        # クラスタidごとの件数集計\n        level_count_df = df.groupby(cluster_columns.id).size().reset_index(name=\"value\")\n\n        level_unique_val_df = df[\n            [cluster_columns.id, cluster_columns.label, cluster_columns.description]\n        ].drop_duplicates()\n        level_unique_val_df = level_unique_val_df.merge(level_count_df, on=cluster_columns.id, how=\"left\")\n        level_unique_vals = [\n            {\n                \"level\": level,\n                \"id\": row[cluster_columns.id],\n                \"label\": row[cluster_columns.label],\n                \"description\": row[cluster_columns.description],\n                \"value\": row[\"value\"],\n            }\n            for _, row in level_unique_val_df.iterrows()\n        ]\n        all_rows.extend(level_unique_vals)\n    return pd.DataFrame(all_rows)\n\n\ndef merge_labelling(clusters_df: pd.DataFrame, cluster_id_columns: list[str], config) -> pd.DataFrame:\n    \"\"\"階層的なクラスタのマージラベリングを実行する\n\n    Args:\n        clusters_df: クラスタリング結果のDataFrame\n        cluster_id_columns: クラスタIDのカラム名のリスト\n        config: 設定情報を含む辞書\n\n    Returns:\n        マージラベリング結果を含むDataFrame\n    \"\"\"\n    for idx in tqdm(range(len(cluster_id_columns) - 1)):\n        previous_columns = ClusterColumns.from_id_column(cluster_id_columns[idx])\n        current_columns = ClusterColumns.from_id_column(cluster_id_columns[idx + 1])\n\n        process_fn = partial(\n            process_merge_labelling,\n            result_df=clusters_df,\n            current_columns=current_columns,\n            previous_columns=previous_columns,\n            config=config,\n        )\n\n        current_cluster_ids = sorted(clusters_df[current_columns.id].unique())\n        with ThreadPoolExecutor(max_workers=config[\"hierarchical_merge_labelling\"][\"workers\"]) as executor:\n            responses = list(\n                tqdm(\n                    executor.map(process_fn, current_cluster_ids),\n                    total=len(current_cluster_ids),\n                )\n            )\n\n        current_result_df = pd.DataFrame(responses)\n        clusters_df = clusters_df.merge(current_result_df, on=[current_columns.id])\n    return clusters_df\n\n\nclass LabellingFromat(BaseModel):\n    \"\"\"ラベリング結果のフォーマットを定義する\"\"\"\n\n    label: str = Field(..., description=\"クラスタのラベル名\")\n    description: str = Field(..., description=\"クラスタの説明文\")\n\n\ndef process_merge_labelling(\n    target_cluster_id: str,\n    result_df: pd.DataFrame,\n    current_columns: ClusterColumns,\n    previous_columns: ClusterColumns,\n    config,\n):\n    \"\"\"個別のクラスタに対してマージラベリングを実行する\n\n    Args:\n        target_cluster_id: 処理対象のクラスタID\n        result_df: クラスタリング結果のDataFrame\n        current_columns: 現在のレベルのカラム情報\n        previous_columns: 前のレベルのカラム情報\n        config: 設定情報を含む辞書\n\n    Returns:\n        マージラベリング結果を含む辞書\n    \"\"\"\n\n    def filter_previous_values(df: pd.DataFrame, previous_columns: ClusterColumns) -> list[ClusterValues]:\n        \"\"\"前のレベルのクラスタ情報を取得する\"\"\"\n        previous_records = df[df[current_columns.id] == target_cluster_id][\n            [previous_columns.label, previous_columns.description]\n        ].drop_duplicates()\n        previous_values = [\n            ClusterValues(\n                label=row[previous_columns.label],\n                description=row[previous_columns.description],\n            )\n            for _, row in previous_records.iterrows()\n        ]\n        return previous_values\n\n    previous_values = filter_previous_values(result_df, previous_columns)\n    if len(previous_values) == 1:\n        return {\n            current_columns.id: target_cluster_id,\n            current_columns.label: previous_values[0].label,\n            current_columns.description: previous_values[0].description,\n        }\n    elif len(previous_values) == 0:\n        raise ValueError(f\"クラスタ {target_cluster_id} には前のレベルのクラスタが存在しません。\")\n\n    current_cluster_data = result_df[result_df[current_columns.id] == target_cluster_id]\n    sampling_num = min(\n        config[\"hierarchical_merge_labelling\"][\"sampling_num\"],\n        len(current_cluster_data),\n    )\n    sampled_data = current_cluster_data.sample(sampling_num)\n    sampled_argument_text = \"\\n\".join(sampled_data[\"argument\"].values)\n    cluster_text = \"\\n\".join([value.to_prompt_text() for value in previous_values])\n    messages = [\n        {\"role\": \"system\", \"content\": config[\"hierarchical_merge_labelling\"][\"prompt\"]},\n        {\n            \"role\": \"user\",\n            \"content\": \"クラスタラベル\\n\" + cluster_text + \"\\n\" + \"クラスタの意見\\n\" + sampled_argument_text,\n        },\n    ]\n    try:\n        response_text, token_input, token_output, token_total = request_to_chat_ai(\n            messages=messages,\n            model=config[\"hierarchical_merge_labelling\"][\"model\"],\n            json_schema=LabellingFromat,\n            provider=config[\"provider\"],\n            local_llm_address=config.get(\"local_llm_address\"),\n        )\n\n        config[\"total_token_usage\"] = config.get(\"total_token_usage\", 0) + token_total\n        config[\"token_usage_input\"] = config.get(\"token_usage_input\", 0) + token_input\n        config[\"token_usage_output\"] = config.get(\"token_usage_output\", 0) + token_output\n        print(f\"Merge labelling: input={token_input}, output={token_output}, total={token_total} tokens\")\n\n        response_json = json.loads(response_text) if isinstance(response_text, str) else response_text\n        return {\n            current_columns.id: target_cluster_id,\n            current_columns.label: response_json.get(\"label\", \"エラーでラベル名が取得できませんでした\"),\n            current_columns.description: response_json.get(\"description\", \"エラーで解説が取得できませんでした\"),\n        }\n    except Exception as e:\n        print(f\"エラーが発生しました: {e}\")\n        return {\n            current_columns.id: target_cluster_id,\n            current_columns.label: \"エラーでラベル名が取得できませんでした\",\n            current_columns.description: \"エラーで解説が取得できませんでした\",\n        }\n\n\ndef calculate_cluster_density(melted_df: pd.DataFrame, config: dict):\n    \"\"\"クラスタ内の密度計算\"\"\"\n    hierarchical_cluster_df = pd.read_csv(f\"outputs/{config['output_dir']}/hierarchical_clusters.csv\")\n\n    densities = []\n    for level, c_id in zip(melted_df[\"level\"], melted_df[\"id\"], strict=False):\n        cluster_embeds = hierarchical_cluster_df[hierarchical_cluster_df[f\"cluster-level-{level}-id\"] == c_id][\n            [\"x\", \"y\"]\n        ].values\n        density = calculate_density(cluster_embeds)\n        densities.append(density)\n\n    # 密度のランクを計算\n    melted_df[\"density\"] = densities\n    melted_df[\"density_rank\"] = melted_df.groupby(\"level\")[\"density\"].rank(ascending=False, method=\"first\")\n    melted_df[\"density_rank_percentile\"] = melted_df.groupby(\"level\")[\"density_rank\"].transform(lambda x: x / len(x))\n    return melted_df\n\n\ndef calculate_density(embeds: np.ndarray):\n    \"\"\"平均距離に基づいて密度を計算\"\"\"\n    center = np.mean(embeds, axis=0)\n    distances = np.linalg.norm(embeds - center, axis=1)\n    avg_distance = np.mean(distances)\n    density = 1 / (avg_distance + 1e-10)\n    return density\n",
          "model": "gpt-4o-mini"
        },
        "token_usage": 4719
      },
      {
        "step": "hierarchical_overview",
        "completed": "2025-08-23T05:15:06.500553",
        "duration": 1.934917,
        "params": {
          "prompt": "/system \n\nあなたはシンクタンクで働く専門のリサーチアシスタントです。\nチームは特定のテーマに関してパブリック・コンサルテーションを実施し、異なる選択肢の意見グループを分析し始めています。\nこれから意見グループのリストとその簡単な分析が提供されます。\nあなたの仕事は、調査結果の簡潔な要約を返すことです。要約は非常に簡潔に（最大で1段落、最大4文）まとめ、無意味な言葉を避けてください。\n出力は日本語で行ってください。\n",
          "source_code": "\"\"\"Create summaries for the clusters.\"\"\"\n\nimport json\nimport re\n\nimport pandas as pd\nfrom pydantic import BaseModel, Field\n\nfrom services.llm import request_to_chat_ai\n\n\nclass OverviewResponse(BaseModel):\n    summary: str = Field(..., description=\"クラスターの全体的な要約\")\n\n\ndef hierarchical_overview(config):\n    dataset = config[\"output_dir\"]\n    path = f\"outputs/{dataset}/hierarchical_overview.txt\"\n\n    hierarchical_label_df = pd.read_csv(f\"outputs/{dataset}/hierarchical_merge_labels.csv\")\n\n    prompt = config[\"hierarchical_overview\"][\"prompt\"]\n    model = config[\"hierarchical_overview\"][\"model\"]\n\n    # TODO: level1で固定にしているが、設定で変えられるようにする\n    target_level = 1\n    target_records = hierarchical_label_df[hierarchical_label_df[\"level\"] == target_level]\n    ids = target_records[\"id\"].to_list()\n    labels = target_records[\"label\"].to_list()\n    descriptions = target_records[\"description\"].to_list()\n    target_records.set_index(\"id\", inplace=True)\n\n    input_text = \"\"\n    for i, _ in enumerate(ids):\n        input_text += f\"# Cluster {i}/{len(ids)}: {labels[i]}\\n\\n\"\n        input_text += descriptions[i] + \"\\n\\n\"\n\n    messages = [{\"role\": \"system\", \"content\": prompt}, {\"role\": \"user\", \"content\": input_text}]\n    response_text, token_input, token_output, token_total = request_to_chat_ai(\n        messages=messages,\n        model=model,\n        provider=config[\"provider\"],\n        local_llm_address=config.get(\"local_llm_address\"),\n        json_schema=OverviewResponse,\n    )\n\n    # トークン使用量を累積\n    config[\"total_token_usage\"] = config.get(\"total_token_usage\", 0) + token_total\n    config[\"token_usage_input\"] = config.get(\"token_usage_input\", 0) + token_input\n    config[\"token_usage_output\"] = config.get(\"token_usage_output\", 0) + token_output\n    print(f\"Hierarchical overview: input={token_input}, output={token_output}, total={token_total} tokens\")\n\n    try:\n        # structured outputとしてパースできるなら処理する\n        if isinstance(response_text, dict):\n            parsed_response = response_text\n        else:\n            parsed_response = json.loads(response_text)\n\n        with open(path, \"w\") as file:\n            file.write(parsed_response[\"summary\"])\n\n    except Exception:\n        # thinkタグが出力されるReasoningモデル用に、thinkタグを除去する\n        thinking_removed = re.sub(\n            r\"<think\\b[^>]*>.*?</think>\",\n            \"\",\n            response_text,\n            flags=re.DOTALL,\n        )\n\n        with open(path, \"w\") as file:\n            file.write(thinking_removed)\n",
          "model": "gpt-4o-mini"
        },
        "token_usage": 898
      }
    ],
    "total_token_usage": 23523,
    "token_usage_input": 20791,
    "token_usage_output": 2732,
    "lock_until": "2025-08-23T05:20:06.506225",
    "current_job": "hierarchical_aggregation",
    "current_job_started": "2025-08-23T05:15:06.506210",
    "estimated_cost": 0.00475785,
    "current_job_progress": null,
    "current_jop_tasks": null
  },
  "comment_num": 20
}